{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df2c0a5e-5934-4d8f-a12c-4f47e1f6c8f5",
   "metadata": {},
   "source": [
    "# Appendix B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7972889b-8b30-4407-bc0e-3f5494bce1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4271c40e-295d-44a6-890e-d68fe4a6cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the raw data\n",
    "raw_train = pd.read_csv(\"data/train.csv\", parse_dates=['host_since', 'first_review', 'last_review'])\n",
    "raw_test = pd.read_csv(\"data/test.csv\", parse_dates=['host_since', 'first_review', 'last_review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be2e53-e6be-4085-b4d1-ac2e07f96575",
   "metadata": {},
   "source": [
    "## Model 1 Feature Engineering\n",
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ae4bf-df3d-4cb3-8067-f561b23f8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that are ready to go out of the box\n",
    "good_to_go_train = raw_train[['host_total_listings_count', 'calculated_host_listings_count',\n",
    "                              'accommodates',\n",
    "                              'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "                              'minimum_nights', 'maximum_nights',\n",
    "                              'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].copy()\n",
    "\n",
    "# features that require transformation from boolean to indicator\n",
    "bools_train = raw_train[['host_is_superhost', \"host_has_profile_pic\", 'host_identity_verified', 'has_availability', 'instant_bookable']].copy()\n",
    "bools_train.loc[bools_train[\"host_is_superhost\"].isna(), 'host_is_superhost'] = False\n",
    "bools_train.loc[bools_train[\"has_availability\"].isna(), 'has_availability'] = False\n",
    "bools_train = bools_train.astype(int)\n",
    "\n",
    "# coordinate and rotated coordinate features\n",
    "# Creating the rotated version such that Manhattan is exactly vertical\n",
    "# so trees can roughly split along streets and avenues\n",
    "coords_train = raw_train[['longitude', 'latitude']].copy()\n",
    "# rotation matrix\n",
    "theta = np.radians(32)\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta), np.cos(theta)]\n",
    "])\n",
    "\n",
    "coords = coords_train[['longitude', 'latitude']].values\n",
    "rotated_coords = coords @ rotation_matrix.T\n",
    "coords_train['Rotated Longitude'] = rotated_coords[:, 0]\n",
    "coords_train['Rotate Latitude'] = rotated_coords[:, 1]\n",
    "\n",
    "# date variables (transform to \"days since\")\n",
    "dates_train = (raw_train[\"host_since\"].max() - raw_train[\"host_since\"]).dt.days\n",
    "\n",
    "# create dummies for categorical vairables\n",
    "categorical_train = raw_train[['neighbourhood_group_cleansed', 'host_response_time', 'room_type']].copy()\n",
    "categorical_train = pd.get_dummies(categorical_train, prefix=[\"Neighborhood Group\", \"Response Time\", \"Room Type\"],\n",
    "                                   prefix_sep = \" : \", dummy_na=True, drop_first=False).drop(columns=[\"Neighborhood Group : nan\", \"Room Type : nan\"]).astype(int)\n",
    "\n",
    "# Create Indicators for Amenities that appear more than 500 times in the training set\n",
    "amenities_as_lists = raw_train['amenities'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\"', '').split(', '))\n",
    "# dictionary of amenities and their counts\n",
    "unique_amenities = {}\n",
    "\n",
    "for list in amenities_as_lists:\n",
    "    for item in list:\n",
    "        if item in unique_amenities:\n",
    "            unique_amenities[item] = unique_amenities[item] + 1\n",
    "        else:\n",
    "            unique_amenities[item] = 1\n",
    "# amenities appearing more than 500 times\n",
    "amenitities_to_dummy = [amenity for amenity, count in unique_amenities.items() if count >= 500]\n",
    "\n",
    "amenity_train = pd.DataFrame({f'Amenity : {amenity}': amenities_as_lists.apply(lambda x: amenity in x) for amenity in amenitities_to_dummy}).astype(int)\n",
    "amenity_train[\"Total Amenities\"] = amenities_as_lists.apply(lambda x : len(x))\n",
    "\n",
    "# features that require imputation and other wrangling\n",
    "wrangle_train = raw_train[[\"host_response_rate\", \"host_acceptance_rate\", \"bathrooms\", \"bedrooms\", \"beds\"]].copy()\n",
    "# impute missingness as its own value\n",
    "wrangle_train.loc[wrangle_train[\"host_response_rate\"].isna(), \"host_response_rate\"] = -1\n",
    "wrangle_train.loc[wrangle_train[\"host_acceptance_rate\"].isna(), \"host_acceptance_rate\"] = -1\n",
    "# impute the mode\n",
    "wrangle_train.loc[wrangle_train[\"bathrooms\"].isna(), \"bathrooms\"] = 1\n",
    "wrangle_train.loc[wrangle_train[\"bedrooms\"].isna(), \"bedrooms\"] = 1\n",
    "wrangle_train.loc[wrangle_train[\"beds\"].isna(), \"beds\"] = 1\n",
    "# Create ratios from calculated counts fields\n",
    "wrangle_train[\"Shared Baths\"] = raw_train[\"bathrooms_text\"].apply(lambda x : \"shared\" in str(x).lower()).astype(int)\n",
    "wrangle_train[\"Calculated Host Proportion : Entire Homes/Apts\"] = raw_train['calculated_host_listings_count_entire_homes'] / raw_train['calculated_host_listings_count']\n",
    "wrangle_train[\"Calculated Host Proportion : Private Rooms\"] = raw_train['calculated_host_listings_count_private_rooms'] / raw_train['calculated_host_listings_count']\n",
    "wrangle_train[\"Calculated Host Proportion : Shared Rooms\"] = raw_train['calculated_host_listings_count_shared_rooms'] / raw_train['calculated_host_listings_count']\n",
    "\n",
    "# join for final data frame\n",
    "model1_train = pd.concat([good_to_go_train, bools_train, coords_train, dates_train, categorical_train, amenity_train, wrangle_train], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90ecf1-90f2-41ab-93be-c2969c768ad5",
   "metadata": {},
   "source": [
    "### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92290d0-4a6f-4134-a22f-f6abab9ceb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that are ready to go out of the box\n",
    "good_to_go_test = raw_test[['host_total_listings_count', 'calculated_host_listings_count',\n",
    "                              'accommodates',\n",
    "                              'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "                              'minimum_nights', 'maximum_nights',\n",
    "                              'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].copy()\n",
    "\n",
    "# features that require transformation from boolean to indicator\n",
    "bools_test = raw_test[['host_is_superhost', \"host_has_profile_pic\", 'host_identity_verified', 'has_availability', 'instant_bookable']].copy()\n",
    "bools_test.loc[bools_test[\"host_is_superhost\"].isna(), 'host_is_superhost'] = False\n",
    "bools_test.loc[bools_test[\"has_availability\"].isna(), 'has_availability'] = False\n",
    "bools_test = bools_test.astype(int)\n",
    "\n",
    "# coordinate and rotated coordinate features\n",
    "# Creating the rotated version such that Manhattan is exactly vertical\n",
    "# so trees can roughly split along streets and avenues\n",
    "coords_test = raw_test[['longitude', 'latitude']].copy()\n",
    "# rotation matrix\n",
    "theta = np.radians(32)\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta), np.cos(theta)]\n",
    "])\n",
    "\n",
    "coords = coords_test[['longitude', 'latitude']].values\n",
    "rotated_coords = coords @ rotation_matrix.T\n",
    "coords_test['Rotated Longitude'] = rotated_coords[:, 0]\n",
    "coords_test['Rotate Latitude'] = rotated_coords[:, 1]\n",
    "\n",
    "# date variables (transform to \"days since\")\n",
    "dates_test = (raw_train[\"host_since\"].max() - raw_test[\"host_since\"]).dt.days\n",
    "\n",
    "# create dummies for categorical vairables\n",
    "categorical_test = raw_test[['neighbourhood_group_cleansed', 'host_response_time', 'room_type']].copy()\n",
    "categorical_test = pd.get_dummies(categorical_test, prefix=[\"Neighborhood Group\", \"Response Time\", \"Room Type\"],\n",
    "                                   prefix_sep = \" : \", dummy_na=True, drop_first=False).drop(columns=[\"Neighborhood Group : nan\", \"Room Type : nan\"]).astype(int)\n",
    "\n",
    "# Create Indicators for Amenities that appear more than 500 times in training set\n",
    "amenities_as_lists = raw_test['amenities'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\"', '').split(', '))\n",
    "\n",
    "amenity_test = pd.DataFrame({f'Amenity : {amenity}': amenities_as_lists.apply(lambda x: amenity in x) for amenity in amenitities_to_dummy}).astype(int)\n",
    "amenity_test[\"Total Amenities\"] = amenities_as_lists.apply(lambda x : len(x))\n",
    "\n",
    "# features that require imputation and other wrangling\n",
    "wrangle_test = raw_test[[\"host_response_rate\", \"host_acceptance_rate\", \"bathrooms\", \"bedrooms\", \"beds\"]].copy()\n",
    "# impute missingness as its own value\n",
    "wrangle_test.loc[wrangle_test[\"host_response_rate\"].isna(), \"host_response_rate\"] = -1\n",
    "wrangle_test.loc[wrangle_test[\"host_acceptance_rate\"].isna(), \"host_acceptance_rate\"] = -1\n",
    "# impute the mode\n",
    "wrangle_test.loc[wrangle_test[\"bathrooms\"].isna(), \"bathrooms\"] = 1\n",
    "wrangle_test.loc[wrangle_test[\"bedrooms\"].isna(), \"bedrooms\"] = 1\n",
    "wrangle_test.loc[wrangle_test[\"beds\"].isna(), \"beds\"] = 1\n",
    "# Create ratios from calculated counts fields\n",
    "wrangle_test[\"Shared Baths\"] = raw_test[\"bathrooms_text\"].apply(lambda x : \"shared\" in str(x).lower()).astype(int)\n",
    "wrangle_test[\"Calculated Host Proportion : Entire Homes/Apts\"] = raw_test['calculated_host_listings_count_entire_homes'] / raw_test['calculated_host_listings_count']\n",
    "wrangle_test[\"Calculated Host Proportion : Private Rooms\"] = raw_test['calculated_host_listings_count_private_rooms'] / raw_test['calculated_host_listings_count']\n",
    "wrangle_test[\"Calculated Host Proportion : Shared Rooms\"] = raw_test['calculated_host_listings_count_shared_rooms'] / raw_test['calculated_host_listings_count']\n",
    "\n",
    "# join for final data frame\n",
    "model1_test = pd.concat([good_to_go_test, bools_test, coords_test, dates_test, categorical_test, amenity_test, wrangle_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6be3cb-1ada-46fc-8775-f127497e933c",
   "metadata": {},
   "source": [
    "### Normalization and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32db71-709b-493c-bcff-8ef8e9a6b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make variable names more readable\n",
    "model1_train.columns = [x.replace(\"_\", \" \") for x in model1_train.columns]\n",
    "model1_test.columns = [x.replace(\"_\", \" \") for x in model1_test.columns]\n",
    "\n",
    "model1_train_norm = model1_train.copy()\n",
    "model1_test_norm = model1_test.copy()\n",
    "# min/max standardization\n",
    "for col in model1_train.columns:\n",
    "    model1_train_norm[col] = model1_train_norm[col] - model1_train[col].min()\n",
    "    model1_train_norm[col] = model1_train_norm[col] / (model1_train[col].max() - model1_train[col].min())\n",
    "\n",
    "    model1_test_norm[col] = model1_test_norm[col] - model1_train[col].min()\n",
    "    model1_test_norm[col] = model1_test_norm[col] / (model1_train[col].max() - model1_train[col].min())\n",
    "# export \n",
    "model1_train_norm.to_csv('data/model1_training_features.csv', index=False)\n",
    "model1_test_norm.to_csv('data/model1_testing_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c20ab6-9db7-46dc-b558-ef453ff3398b",
   "metadata": {},
   "source": [
    "## Model 2 Feature Engineering\n",
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b91828-f921-453c-9afb-7f37a8f692c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that are ready to go out of the box\n",
    "good_to_go_train = raw_train[['host_total_listings_count', 'calculated_host_listings_count',\n",
    "                              'accommodates',\n",
    "                              'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "                              'minimum_nights', 'maximum_nights',\n",
    "                              'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].copy()\n",
    "\n",
    "# features that require transformation from boolean to indicator\n",
    "bools_train = raw_train[['host_is_superhost', \"host_has_profile_pic\", 'host_identity_verified', 'has_availability', 'instant_bookable']].copy()\n",
    "bools_train.loc[bools_train[\"host_is_superhost\"].isna(), 'host_is_superhost'] = False\n",
    "bools_train.loc[bools_train[\"has_availability\"].isna(), 'has_availability'] = False\n",
    "bools_train = bools_train.astype(int)\n",
    "\n",
    "# coordinate and rotated coordinate features\n",
    "# Creating the rotated version such that Manhattan is exactly vertical\n",
    "# so trees can roughly split along streets and avenues\n",
    "coords_train = raw_train[['longitude', 'latitude']].copy()\n",
    "\n",
    "theta = np.radians(32)\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta), np.cos(theta)]\n",
    "])\n",
    "\n",
    "coords = coords_train[['longitude', 'latitude']].values\n",
    "rotated_coords = coords @ rotation_matrix.T\n",
    "coords_train['Rotated Longitude'] = rotated_coords[:, 0]-\n",
    "coords_train['Rotate Latitude'] = rotated_coords[:, 1]\n",
    "\n",
    "# date variables (transform to \"days since\")\n",
    "dates_train = (raw_train[\"host_since\"].max() - raw_train[\"host_since\"]).dt.days\n",
    "\n",
    "# create dummies for categorical vairables\n",
    "# Filter for neighborhoods wth over 20 properties in the training dataset to create dummy varaibles\n",
    "hoods = raw_train[\"neighbourhood_cleansed\"].value_counts()\n",
    "hoods_to_dummy = (hoods[hoods >= 20].index).tolist()\n",
    "# Filter for property types with more than 20 properties in the training dataset to create dummy variables\n",
    "prop_types = raw_train[\"property_type\"].value_counts()\n",
    "prop_types_to_dummy = (prop_types[prop_types >= 20].index).tolist()\n",
    "\n",
    "categorical_train = raw_train[['property_type', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'host_response_time', 'room_type']].copy()\n",
    "categorical_train.loc[categorical_train[\"property_type\"].apply(lambda x : x not in prop_types_to_dummy), \"property_type\"] = \"Other\"\n",
    "categorical_train.loc[categorical_train[\"neighbourhood_cleansed\"].apply(lambda x : x not in hoods_to_dummy), \"neighbourhood_cleansed\"] = \"Other\"\n",
    "categorical_train = pd.get_dummies(categorical_train, prefix=[\"Property Type\", \"Neighborhood\", \"Neighborhood Group\", \"Response Time\", \"Room Type\"],\n",
    "                                   prefix_sep = \" : \", dummy_na=True, drop_first=False).drop(columns=[\"Property Type : nan\",\n",
    "                                                                                                      \"Neighborhood : nan\",\n",
    "                                                                                                      \"Neighborhood Group : nan\",\n",
    "                                                                                                      \"Room Type : nan\"]).astype(int)\n",
    "\n",
    "# Create Indicators for Amenities that appear more than 100 times in training set\n",
    "amenities_as_lists = raw_train['amenities'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\"', '').split(', '))\n",
    "\n",
    "unique_amenities = {}\n",
    "\n",
    "for list in amenities_as_lists:\n",
    "    for item in list:\n",
    "        if item in unique_amenities:\n",
    "            unique_amenities[item] = unique_amenities[item] + 1\n",
    "        else:\n",
    "            unique_amenities[item] = 1\n",
    "\n",
    "amenitities_to_dummy = [amenity for amenity, count in unique_amenities.items() if count >= 100]\n",
    "\n",
    "amenity_train = pd.DataFrame({f'Amenity : {amenity}': amenities_as_lists.apply(lambda x: amenity in x) for amenity in amenitities_to_dummy}).astype(int)\n",
    "amenity_train[\"Total Amenities\"] = amenities_as_lists.apply(lambda x : len(x))\n",
    "\n",
    "# features that require imputation and other wrangling\n",
    "wrangle_train = raw_train[[\"host_response_rate\", \"host_acceptance_rate\", \"bathrooms\", \"bedrooms\", \"beds\"]].copy()\n",
    "# impute missingness as its own value\n",
    "wrangle_train.loc[wrangle_train[\"host_response_rate\"].isna(), \"host_response_rate\"] = -1\n",
    "wrangle_train.loc[wrangle_train[\"host_acceptance_rate\"].isna(), \"host_acceptance_rate\"] = -1\n",
    "# impute the mode\n",
    "wrangle_train.loc[wrangle_train[\"bathrooms\"].isna(), \"bathrooms\"] = 1\n",
    "wrangle_train.loc[wrangle_train[\"bedrooms\"].isna(), \"bedrooms\"] = 1\n",
    "wrangle_train.loc[wrangle_train[\"beds\"].isna(), \"beds\"] = 1\n",
    "# Create ratios from calculated counts fields\n",
    "wrangle_train[\"Shared Baths\"] = raw_train[\"bathrooms_text\"].apply(lambda x : \"shared\" in str(x).lower()).astype(int)\n",
    "wrangle_train[\"Calculated Host Proportion : Entire Homes/Apts\"] = raw_train['calculated_host_listings_count_entire_homes'] / raw_train['calculated_host_listings_count']\n",
    "wrangle_train[\"Calculated Host Proportion : Private Rooms\"] = raw_train['calculated_host_listings_count_private_rooms'] / raw_train['calculated_host_listings_count']\n",
    "wrangle_train[\"Calculated Host Proportion : Shared Rooms\"] = raw_train['calculated_host_listings_count_shared_rooms'] / raw_train['calculated_host_listings_count']\n",
    "\n",
    "# Curate All review Data\n",
    "review_train = raw_train[['first_review', 'last_review',\n",
    "                          'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']].copy()\n",
    "# impute min/max value and take \"\"days since\"\n",
    "review_train.loc[review_train[\"first_review\"].isna(), 'first_review'] = raw_train[\"first_review\"].max()\n",
    "review_train.loc[review_train[\"last_review\"].isna(), 'last_review'] = raw_train[\"last_review\"].min()\n",
    "review_train[\"first_review\"] = (raw_train[\"first_review\"].max() - review_train[\"first_review\"]).dt.days\n",
    "review_train[\"last_review\"] = (raw_train[\"last_review\"].max() - review_train[\"last_review\"]).dt.days\n",
    "# impute missingness as its own value\n",
    "review_train.loc[review_train[\"review_scores_rating\"].isna(), 'review_scores_rating'] = -1\n",
    "review_train.loc[review_train[\"review_scores_accuracy\"].isna(), 'review_scores_accuracy'] = -1\n",
    "review_train.loc[review_train[\"review_scores_cleanliness\"].isna(), 'review_scores_cleanliness'] = -1\n",
    "review_train.loc[review_train[\"review_scores_checkin\"].isna(), 'review_scores_checkin'] = -1\n",
    "review_train.loc[review_train[\"review_scores_communication\"].isna(), 'review_scores_communication'] = -1\n",
    "review_train.loc[review_train[\"review_scores_location\"].isna(), 'review_scores_location'] = -1\n",
    "review_train.loc[review_train[\"review_scores_value\"].isna(), 'review_scores_value'] = -1\n",
    "\n",
    "review_train[\"Has Reviews\"] = (raw_train[\"number_of_reviews\"] == 0).astype(int)\n",
    "\n",
    "# join for final data frame\n",
    "model2_train = pd.concat([good_to_go_train, bools_train, coords_train, dates_train, categorical_train, amenity_train, wrangle_train, review_train], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b92c7-5bb9-4964-a587-0e8ee1714dad",
   "metadata": {},
   "source": [
    "### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8f6b2-a67d-44f3-bdf2-8099731e310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features that are ready to go out of the box\n",
    "good_to_go_test = raw_test[['host_total_listings_count', 'calculated_host_listings_count',\n",
    "                              'accommodates',\n",
    "                              'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "                              'minimum_nights', 'maximum_nights',\n",
    "                              'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].copy()\n",
    "\n",
    "# features that require transformation from boolean to indicator\n",
    "bools_test = raw_test[['host_is_superhost', \"host_has_profile_pic\", 'host_identity_verified', 'has_availability', 'instant_bookable']].copy()\n",
    "bools_test.loc[bools_test[\"host_is_superhost\"].isna(), 'host_is_superhost'] = False\n",
    "bools_test.loc[bools_test[\"has_availability\"].isna(), 'has_availability'] = False\n",
    "bools_test = bools_test.astype(int)\n",
    "\n",
    "# coordinate and rotated coordinate features\n",
    "# Creating the rotated version such that Manhattan is exactly vertical\n",
    "# so trees can roughly split along streets and avenues\n",
    "coords_test = raw_test[['longitude', 'latitude']].copy()\n",
    "\n",
    "theta = np.radians(32)\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta), np.cos(theta)]\n",
    "])\n",
    "\n",
    "coords = coords_test[['longitude', 'latitude']].values\n",
    "rotated_coords = coords @ rotation_matrix.T\n",
    "coords_test['Rotated Longitude'] = rotated_coords[:, 0]\n",
    "coords_test['Rotate Latitude'] = rotated_coords[:, 1]\n",
    "\n",
    "# date variables (transform to \"days since\")\n",
    "dates_test = (raw_train[\"host_since\"].max() - raw_test[\"host_since\"]).dt.days\n",
    "\n",
    "# create dummies for categorical vairables\n",
    "categorical_test = raw_test[['property_type', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'host_response_time', 'room_type']].copy()\n",
    "categorical_test.loc[categorical_test[\"property_type\"].apply(lambda x : x not in prop_types_to_dummy), \"property_type\"] = \"Other\"\n",
    "categorical_test.loc[categorical_test[\"neighbourhood_cleansed\"].apply(lambda x : x not in hoods_to_dummy), \"neighbourhood_cleansed\"] = \"Other\"\n",
    "categorical_test = pd.get_dummies(categorical_test, prefix=[\"Property Type\", \"Neighborhood\", \"Neighborhood Group\", \"Response Time\", \"Room Type\"],\n",
    "                                   prefix_sep = \" : \", dummy_na=True, drop_first=False).drop(columns=[\"Property Type : nan\",\n",
    "                                                                                                      \"Neighborhood : nan\",\n",
    "                                                                                                      \"Neighborhood Group : nan\",\n",
    "                                                                                                      \"Room Type : nan\"]).astype(int)\n",
    "\n",
    "# Create Indicators for Amenities that appear more than 100 times in the training set\n",
    "amenities_as_lists = raw_test['amenities'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\"', '').split(', '))\n",
    "\n",
    "amenity_test = pd.DataFrame({f'Amenity : {amenity}': amenities_as_lists.apply(lambda x: amenity in x) for amenity in amenitities_to_dummy}).astype(int)\n",
    "amenity_test[\"Total Amenities\"] = amenities_as_lists.apply(lambda x : len(x))\n",
    "\n",
    "# features that require imputation and other wrangling\n",
    "wrangle_test = raw_test[[\"host_response_rate\", \"host_acceptance_rate\", \"bathrooms\", \"bedrooms\", \"beds\"]].copy()\n",
    "# impute missingness as its own value\n",
    "wrangle_test.loc[wrangle_test[\"host_response_rate\"].isna(), \"host_response_rate\"] = -1\n",
    "wrangle_test.loc[wrangle_test[\"host_acceptance_rate\"].isna(), \"host_acceptance_rate\"] = -1\n",
    "# impute the mode\n",
    "wrangle_test.loc[wrangle_test[\"bathrooms\"].isna(), \"bathrooms\"] = 1\n",
    "wrangle_test.loc[wrangle_test[\"bedrooms\"].isna(), \"bedrooms\"] = 1\n",
    "wrangle_test.loc[wrangle_test[\"beds\"].isna(), \"beds\"] = 1\n",
    "# Create ratios from calculated counts fields\n",
    "wrangle_test[\"Shared Baths\"] = raw_test[\"bathrooms_text\"].apply(lambda x : \"shared\" in str(x).lower()).astype(int)\n",
    "wrangle_test[\"Calculated Host Proportion : Entire Homes/Apts\"] = raw_test['calculated_host_listings_count_entire_homes'] / raw_test['calculated_host_listings_count']\n",
    "wrangle_test[\"Calculated Host Proportion : Private Rooms\"] = raw_test['calculated_host_listings_count_private_rooms'] / raw_test['calculated_host_listings_count']\n",
    "wrangle_test[\"Calculated Host Proportion : Shared Rooms\"] = raw_test['calculated_host_listings_count_shared_rooms'] / raw_test['calculated_host_listings_count']\n",
    "\n",
    "# Curate all Review Data\n",
    "review_test = raw_test[['first_review', 'last_review',\n",
    "                          'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']].copy()\n",
    "# impute min/max value and take \"\"days since\"\n",
    "review_test.loc[review_test[\"first_review\"].isna(), 'first_review'] = raw_train[\"first_review\"].max()\n",
    "review_test.loc[review_test[\"last_review\"].isna(), 'last_review'] = raw_train[\"last_review\"].min()\n",
    "review_test[\"first_review\"] = (raw_train[\"first_review\"].max() - review_test[\"first_review\"]).dt.days\n",
    "review_test[\"last_review\"] = (raw_train[\"last_review\"].max() - review_test[\"last_review\"]).dt.days\n",
    "# impute missingness as its own value\n",
    "review_test.loc[review_test[\"review_scores_rating\"].isna(), 'review_scores_rating'] = -1\n",
    "review_test.loc[review_test[\"review_scores_accuracy\"].isna(), 'review_scores_accuracy'] = -1\n",
    "review_test.loc[review_test[\"review_scores_cleanliness\"].isna(), 'review_scores_cleanliness'] = -1\n",
    "review_test.loc[review_test[\"review_scores_checkin\"].isna(), 'review_scores_checkin'] = -1\n",
    "review_test.loc[review_test[\"review_scores_communication\"].isna(), 'review_scores_communication'] = -1\n",
    "review_test.loc[review_test[\"review_scores_location\"].isna(), 'review_scores_location'] = -1\n",
    "review_test.loc[review_test[\"review_scores_value\"].isna(), 'review_scores_value'] = -1\n",
    "\n",
    "review_test[\"Has Reviews\"] = (raw_test[\"number_of_reviews\"] == 0).astype(int)\n",
    "\n",
    "# join for final data frame\n",
    "model2_test = pd.concat([good_to_go_test, bools_test, coords_test, dates_test, categorical_test, amenity_test, wrangle_test, review_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac71a5-cf9b-48fd-a436-2efcb9ea410c",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674269b6-6e27-4fb6-a2bc-e4290aca6333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make feature names more readable\n",
    "model2_train.columns = [x.replace(\"_\", \" \") for x in model2_train.columns]\n",
    "model2_test.columns = [x.replace(\"_\", \" \") for x in model2_test.columns]\n",
    "\n",
    "model2_train_norm = model2_train.copy()\n",
    "model2_test_norm = model2_test.copy()\n",
    "# min/max standardization\n",
    "for col in model2_train.columns:\n",
    "    model2_train_norm[col] = model2_train_norm[col] - model2_train[col].min()\n",
    "    model2_train_norm[col] = model2_train_norm[col] / (model2_train[col].max() - model2_train[col].min())\n",
    "\n",
    "    model2_test_norm[col] = model2_test_norm[col] - model2_train[col].min()\n",
    "    model2_test_norm[col] = model2_test_norm[col] / (model2_train[col].max() - model2_train[col].min())\n",
    "# export\n",
    "model2_train_norm.to_csv('data/model2_training_features.csv', index=False)\n",
    "model2_test_norm.to_csv('data/model2_testing_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12d5b7-5d44-4033-b13b-92b5f4015e7d",
   "metadata": {},
   "source": [
    "## Model 3 Feature Engineering\n",
    "\n",
    "### Computing Influential N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482389f1-77bc-4324-8cc9-ccbecfecda1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to replace punctuation with white space\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Remove punctuation\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c165ce-ee15-41bb-90a7-b2ea5d89ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_descriptions = raw_train['description'].fillna(\"\")\n",
    "clean_reviews = raw_train['reviews'].fillna(\"\")\n",
    "# Clean all textual data\n",
    "clean_names = raw_train['name'].apply(clean_text)\n",
    "clean_descriptions = clean_descriptions.apply(clean_text)\n",
    "clean_reviews = clean_reviews.apply(clean_text).apply(lambda x : re.sub(r'\\n', '', x))\n",
    "# generate indicators for the occurrence of frequent n-grams\n",
    "name_vectorizer = CountVectorizer(ngram_range=(1, 5), min_df=50)\n",
    "description_vectorizer = CountVectorizer(ngram_range=(2, 6), min_df=150)\n",
    "review_vectorizer = CountVectorizer(ngram_range=(3, 3), min_df=350)\n",
    "# Create data frames out of the indicators\n",
    "name_ngrams = pd.DataFrame(name_vectorizer.fit_transform(clean_names).toarray(),\n",
    "                           columns = name_vectorizer.get_feature_names_out())\n",
    "description_ngrams = pd.DataFrame(description_vectorizer.fit_transform(clean_descriptions).toarray(),\n",
    "                                  columns = description_vectorizer.get_feature_names_out())\n",
    "review_ngrams = pd.DataFrame(review_vectorizer.fit_transform(clean_reviews).toarray(),\n",
    "                                  columns = review_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d9289-6baf-432e-961c-5b1595daae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute approximate mutual information of these indicators with the response variable\n",
    "name_ngram_mututal_information = mutual_info_regression(name_ngrams, raw_train['price'])\n",
    "description_ngram_mututal_information = mutual_info_regression(description_ngrams, raw_train['price'])\n",
    "review_ngram_mututal_information = mutual_info_regression(review_ngrams, raw_train['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4361b-3cf3-4f81-a179-b98bcb2d91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take n-gram indicators with the most mutual information with the response variable\n",
    "name_top50 = [feature for _, feature in sorted(zip(name_ngram_mututal_information, name_ngrams.columns), reverse=True)[:50]]\n",
    "description_top100 = [feature for _, feature in sorted(zip(description_ngram_mututal_information, description_ngrams.columns), reverse=True)[:100]]\n",
    "review_top100 = [feature for _, feature in sorted(zip(review_ngram_mututal_information, review_ngrams.columns), reverse=True)[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c08ff-c5ef-4ac2-9ec7-039d4d970768",
   "metadata": {},
   "source": [
    "### Creating Textual Training/Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928102f9-ed0f-422e-9c0a-565843019aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_descriptions_test = raw_test['description'].fillna(\"\")\n",
    "clean_reviews_test = raw_test['reviews'].fillna(\"\")\n",
    "\n",
    "clean_names_test = raw_test['name'].apply(clean_text)\n",
    "clean_descriptions_test = clean_descriptions_test.apply(clean_text)\n",
    "clean_reviews_test = clean_reviews_test.apply(clean_text).apply(lambda x : re.sub(r'\\n', '', x))\n",
    "\n",
    "# Recreate transformers for chosen n-grams \n",
    "name_transformer = CountVectorizer(ngram_range=(1, 5), vocabulary=name_top50)\n",
    "description_transformer = CountVectorizer(ngram_range=(2, 6), vocabulary=description_top100)\n",
    "review_transformer = CountVectorizer(ngram_range=(3, 3), vocabulary=review_top100)\n",
    "# Create testing and training indicators\n",
    "name_ngrams_train = pd.DataFrame(name_transformer.transform(clean_names).toarray(),\n",
    "                                 columns = [f'Name NGram : {gram}' for gram in name_transformer.get_feature_names_out()])\n",
    "description_ngrams_train = pd.DataFrame(description_transformer.transform(clean_descriptions).toarray(),\n",
    "                                        columns = [f'Description NGram : {gram}' for gram in description_transformer.get_feature_names_out()])\n",
    "review_ngrams_train = pd.DataFrame(review_transformer.transform(clean_reviews).toarray(),\n",
    "                                        columns = [f'Review NGram : {gram}' for gram in review_transformer.get_feature_names_out()])\n",
    "\n",
    "name_ngrams_test = pd.DataFrame(name_transformer.transform(clean_names_test).toarray(),\n",
    "                                columns = [f'Name NGram : {gram}' for gram in name_transformer.get_feature_names_out()])\n",
    "description_ngrams_test = pd.DataFrame(description_transformer.transform(clean_descriptions_test).toarray(),\n",
    "                                       columns = [f'Description NGram : {gram}' for gram in description_transformer.get_feature_names_out()])\n",
    "review_ngrams_test = pd.DataFrame(review_transformer.transform(clean_reviews_test).toarray(),\n",
    "                                        columns = [f'Review NGram : {gram}' for gram in review_transformer.get_feature_names_out()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646e2b11-2c51-4fc7-97b4-de24b8f3e495",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb13a007-3be2-463b-98a4-e21725e7b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with existing model 2 data\n",
    "model3_train = pd.concat([model2_train, name_ngrams_train, description_ngrams_train, review_ngrams_train], axis=1)\n",
    "model3_test = pd.concat([model2_test, name_ngrams_test, description_ngrams_test, review_ngrams_test], axis=1)\n",
    "\n",
    "model3_train_norm = model3_train.copy()\n",
    "model3_test_norm = model3_test.copy()\n",
    "# Mean/std normalization\n",
    "for col in model2_train.columns:\n",
    "    model3_train_norm[col] = model3_train_norm[col] - model3_train[col].mean()\n",
    "    model3_train_norm[col] = model3_train_norm[col] / model3_train[col].std()\n",
    "\n",
    "    model3_test_norm[col] = model3_test_norm[col] - model3_train[col].mean()\n",
    "    model3_test_norm[col] = model3_test_norm[col] / model3_train[col].std()\n",
    "# Export\n",
    "model3_train_norm.to_csv('data/model3_training_features.csv', index=False)\n",
    "model3_test_norm.to_csv('data/model3_testing_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
