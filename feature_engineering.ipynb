{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybHitVs3EzFs"
      },
      "source": [
        "# Import Packages & Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llfb7Y4HEzFx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzxwEdC2EzF0"
      },
      "outputs": [],
      "source": [
        "raw_train = pd.read_csv(\"data/train.csv\", parse_dates=['host_since', 'first_review', 'last_review'])\n",
        "raw_test = pd.read_csv(\"data/test.csv\", parse_dates=['host_since', 'first_review', 'last_review'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acNIw9v-EzF1"
      },
      "source": [
        "# Model 1: Interpretability\n",
        "\n",
        "## Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_CxYfANEzF2"
      },
      "outputs": [],
      "source": [
        "# features that are ready to go out of the box\n",
        "good_to_go_train = raw_train[['host_total_listings_count', 'calculated_host_listings_count',\n",
        "                              'accommodates',\n",
        "                              'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
        "                              'minimum_nights', 'maximum_nights',\n",
        "                              'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].copy()\n",
        "\n",
        "# features that require transformation from boolean to indicator\n",
        "bools_train = raw_train[['host_is_superhost', \"host_has_profile_pic\", 'host_identity_verified', 'has_availability', 'instant_bookable']].copy()\n",
        "bools_train.loc[bools_train[\"host_is_superhost\"].isna(), 'host_is_superhost'] = False\n",
        "bools_train.loc[bools_train[\"has_availability\"].isna(), 'has_availability'] = False\n",
        "bools_train = bools_train.astype(int)\n",
        "\n",
        "# coordinate and rotated coordinate features\n",
        "coords_train = raw_train[['longitude', 'latitude']].copy()\n",
        "\n",
        "theta = np.radians(32)\n",
        "rotation_matrix = np.array([\n",
        "    [np.cos(theta), -np.sin(theta)],\n",
        "    [np.sin(theta), np.cos(theta)]\n",
        "])\n",
        "\n",
        "coords = coords_train[['longitude', 'latitude']].values\n",
        "rotated_coords = coords @ rotation_matrix.T\n",
        "coords_train['Rotated Longitude'] = rotated_coords[:, 0]\n",
        "coords_train['Rotate Latitude'] = rotated_coords[:, 1]\n",
        "\n",
        "# date variables\n",
        "dates_train = (raw_train[\"host_since\"].max() - raw_train[\"host_since\"]).dt.days\n",
        "\n",
        "# create dummies for categorical vairables\n",
        "categorical_train = raw_train[['neighbourhood_group_cleansed', 'host_response_time', 'room_type']].copy()\n",
        "categorical_train = pd.get_dummies(categorical_train, prefix=[\"Neighborhood Group\", \"Response Time\", \"Room Type\"],\n",
        "                                   prefix_sep = \" : \", dummy_na=True, drop_first=False).drop(columns=[\"Neighborhood Group : nan\", \"Room Type : nan\"]).astype(int)\n",
        "\n",
        "# Create Indicators for Amenities that appear more than 500 times in training set (maybe add more for more complex models)\n",
        "amenities_as_lists = raw_train['amenities'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\"', '').split(', '))\n",
        "\n",
        "unique_amenities = {}\n",
        "\n",
        "for list in amenities_as_lists:\n",
        "    for item in list:\n",
        "        if item in unique_amenities:\n",
        "            unique_amenities[item] = unique_amenities[item] + 1\n",
        "        else:\n",
        "            unique_amenities[item] = 1\n",
        "\n",
        "amenitities_to_dummy = [amenity for amenity, count in unique_amenities.items() if count >= 500]\n",
        "\n",
        "amenity_train = pd.DataFrame({f'Amenity : {amenity}': amenities_as_lists.apply(lambda x: amenity in x) for amenity in amenitities_to_dummy}).astype(int)\n",
        "amenity_train[\"Total Amenities\"] = amenities_as_lists.apply(lambda x : len(x))\n",
        "\n",
        "# features that require imputation and other wrangling (need to revisit imputation in more complex models)\n",
        "wrangle_train = raw_train[[\"host_response_rate\", \"host_acceptance_rate\", \"bathrooms\", \"bedrooms\", \"beds\"]].copy()\n",
        "\n",
        "wrangle_train.loc[wrangle_train[\"host_response_rate\"].isna(), \"host_response_rate\"] = -1\n",
        "wrangle_train.loc[wrangle_train[\"host_acceptance_rate\"].isna(), \"host_acceptance_rate\"] = -1\n",
        "\n",
        "wrangle_train.loc[wrangle_train[\"bathrooms\"].isna(), \"bathrooms\"] = 1\n",
        "wrangle_train.loc[wrangle_train[\"bedrooms\"].isna(), \"bedrooms\"] = 1\n",
        "wrangle_train.loc[wrangle_train[\"beds\"].isna(), \"beds\"] = 1\n",
        "\n",
        "wrangle_train[\"Shared Baths\"] = raw_train[\"bathrooms_text\"].apply(lambda x : \"shared\" in str(x).lower()).astype(int)\n",
        "wrangle_train[\"Calculated Host Proportion : Entire Homes/Apts\"] = raw_train['calculated_host_listings_count_entire_homes'] / raw_train['calculated_host_listings_count']\n",
        "wrangle_train[\"Calculated Host Proportion : Private Rooms\"] = raw_train['calculated_host_listings_count_private_rooms'] / raw_train['calculated_host_listings_count']\n",
        "wrangle_train[\"Calculated Host Proportion : Shared Rooms\"] = raw_train['calculated_host_listings_count_shared_rooms'] / raw_train['calculated_host_listings_count']\n",
        "\n",
        "# join for final dataframe\n",
        "model1_train = pd.concat([good_to_go_train, bools_train, coords_train, dates_train, categorical_train, amenity_train, wrangle_train], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQKdLEmpEzF4"
      },
      "source": [
        "## Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOXtRRitEzF4"
      },
      "outputs": [],
      "source": [
        "# features that are ready to go out of the box\n",
        "good_to_go_test = raw_test[['host_total_listings_count', 'calculated_host_listings_count',\n",
        "                              'accommodates',\n",
        "                              'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
        "                              'minimum_nights', 'maximum_nights',\n",
        "                              'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].copy()\n",
        "\n",
        "# features that require transformation from boolean to indicator\n",
        "bools_test = raw_test[['host_is_superhost', \"host_has_profile_pic\", 'host_identity_verified', 'has_availability', 'instant_bookable']].copy()\n",
        "bools_test.loc[bools_test[\"host_is_superhost\"].isna(), 'host_is_superhost'] = False\n",
        "bools_test.loc[bools_test[\"has_availability\"].isna(), 'has_availability'] = False\n",
        "bools_test = bools_test.astype(int)\n",
        "\n",
        "# coordinate and rotated coordinate features\n",
        "coords_test = raw_test[['longitude', 'latitude']].copy()\n",
        "\n",
        "theta = np.radians(32)\n",
        "rotation_matrix = np.array([\n",
        "    [np.cos(theta), -np.sin(theta)],\n",
        "    [np.sin(theta), np.cos(theta)]\n",
        "])\n",
        "\n",
        "coords = coords_test[['longitude', 'latitude']].values\n",
        "rotated_coords = coords @ rotation_matrix.T\n",
        "coords_test['Rotated Longitude'] = rotated_coords[:, 0]\n",
        "coords_test['Rotate Latitude'] = rotated_coords[:, 1]\n",
        "\n",
        "# date variables\n",
        "dates_test = (raw_train[\"host_since\"].max() - raw_test[\"host_since\"]).dt.days\n",
        "\n",
        "# create dummies for categorical vairables\n",
        "categorical_test = raw_test[['neighbourhood_group_cleansed', 'host_response_time', 'room_type']].copy()\n",
        "categorical_test = pd.get_dummies(categorical_test, prefix=[\"Neighborhood Group\", \"Response Time\", \"Room Type\"],\n",
        "                                   prefix_sep = \" : \", dummy_na=True, drop_first=False).drop(columns=[\"Neighborhood Group : nan\", \"Room Type : nan\"]).astype(int)\n",
        "\n",
        "# Create Indicators for Amenities that appear more than 500 times in training set (maybe add more for more complex models)\n",
        "amenities_as_lists = raw_test['amenities'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\"', '').split(', '))\n",
        "\n",
        "amenity_test = pd.DataFrame({f'Amenity : {amenity}': amenities_as_lists.apply(lambda x: amenity in x) for amenity in amenitities_to_dummy}).astype(int)\n",
        "amenity_test[\"Total Amenities\"] = amenities_as_lists.apply(lambda x : len(x))\n",
        "\n",
        "# features that require imputation and other wrangling (need to revisit imputation in more complex models)\n",
        "wrangle_test = raw_test[[\"host_response_rate\", \"host_acceptance_rate\", \"bathrooms\", \"bedrooms\", \"beds\"]].copy()\n",
        "\n",
        "wrangle_test.loc[wrangle_test[\"host_response_rate\"].isna(), \"host_response_rate\"] = -1\n",
        "wrangle_test.loc[wrangle_test[\"host_acceptance_rate\"].isna(), \"host_acceptance_rate\"] = -1\n",
        "\n",
        "wrangle_test.loc[wrangle_test[\"bathrooms\"].isna(), \"bathrooms\"] = 1\n",
        "wrangle_test.loc[wrangle_test[\"bedrooms\"].isna(), \"bedrooms\"] = 1\n",
        "wrangle_test.loc[wrangle_test[\"beds\"].isna(), \"beds\"] = 1\n",
        "\n",
        "wrangle_test[\"Shared Baths\"] = raw_test[\"bathrooms_text\"].apply(lambda x : \"shared\" in str(x).lower()).astype(int)\n",
        "wrangle_test[\"Calculated Host Proportion : Entire Homes/Apts\"] = raw_test['calculated_host_listings_count_entire_homes'] / raw_test['calculated_host_listings_count']\n",
        "wrangle_test[\"Calculated Host Proportion : Private Rooms\"] = raw_test['calculated_host_listings_count_private_rooms'] / raw_test['calculated_host_listings_count']\n",
        "wrangle_test[\"Calculated Host Proportion : Shared Rooms\"] = raw_test['calculated_host_listings_count_shared_rooms'] / raw_test['calculated_host_listings_count']\n",
        "\n",
        "# join for final dataframe\n",
        "model1_test = pd.concat([good_to_go_test, bools_test, coords_test, dates_test, categorical_test, amenity_test, wrangle_test], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJMDbgeEEzF6"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl0jAZWGEzF6"
      },
      "outputs": [],
      "source": [
        "model1_train.columns = [x.replace(\"_\", \" \") for x in model1_train.columns]\n",
        "model1_test.columns = [x.replace(\"_\", \" \") for x in model1_test.columns]\n",
        "\n",
        "model1_train_norm = model1_train.copy()\n",
        "model1_test_norm = model1_test.copy()\n",
        "\n",
        "for col in model1_train.columns:\n",
        "    model1_train_norm[col] = model1_train_norm[col] - model1_train[col].min()\n",
        "    model1_train_norm[col] = model1_train_norm[col] / (model1_train[col].max() - model1_train[col].min())\n",
        "\n",
        "    model1_test_norm[col] = model1_test_norm[col] - model1_train[col].min()\n",
        "    model1_test_norm[col] = model1_test_norm[col] / (model1_train[col].max() - model1_train[col].min())\n",
        "\n",
        "model1_train_norm.to_csv('data/model1_training_features.csv', index=False)\n",
        "model1_test_norm.to_csv('data/model1_testing_features.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SvUiHBHEzF7"
      },
      "source": [
        "# Model 2 : Increasing Complexity and Amount of Data\n",
        "## Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc15TGrXEzF9"
      },
      "outputs": [],
      "source": [
        "# features that are ready to go out of the box\n",
        "good_to_go_train = raw_train[['host_total_listings_count', 'calculated_host_listings_count',\n",
        "                              'accommodates',\n",
        "                              'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
        "                              'minimum_nights', 'maximum_nights',\n",
        "                              'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].copy()\n",
        "\n",
        "# features that require transformation from boolean to indicator\n",
        "bools_train = raw_train[['host_is_superhost', \"host_has_profile_pic\", 'host_identity_verified', 'has_availability', 'instant_bookable']].copy()\n",
        "bools_train.loc[bools_train[\"host_is_superhost\"].isna(), 'host_is_superhost'] = False\n",
        "bools_train.loc[bools_train[\"has_availability\"].isna(), 'has_availability'] = False\n",
        "bools_train = bools_train.astype(int)\n",
        "\n",
        "# coordinate and rotated coordinate features\n",
        "coords_train = raw_train[['longitude', 'latitude']].copy()\n",
        "\n",
        "theta = np.radians(32)\n",
        "rotation_matrix = np.array([\n",
        "    [np.cos(theta), -np.sin(theta)],\n",
        "    [np.sin(theta), np.cos(theta)]\n",
        "])\n",
        "\n",
        "coords = coords_train[['longitude', 'latitude']].values\n",
        "rotated_coords = coords @ rotation_matrix.T\n",
        "coords_train['Rotated Longitude'] = rotated_coords[:, 0]\n",
        "coords_train['Rotate Latitude'] = rotated_coords[:, 1]\n",
        "\n",
        "# date variables\n",
        "dates_train = (raw_train[\"host_since\"].max() - raw_train[\"host_since\"]).dt.days\n",
        "\n",
        "# create dummies for categorical vairables\n",
        "hoods = raw_train[\"neighbourhood_cleansed\"].value_counts()\n",
        "hoods_to_dummy = (hoods[hoods >= 20].index).tolist()\n",
        "\n",
        "prop_types = raw_train[\"property_type\"].value_counts()\n",
        "prop_types_to_dummy = (prop_types[prop_types >= 20].index).tolist()\n",
        "\n",
        "categorical_train = raw_train[['property_type', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'host_response_time', 'room_type']].copy()\n",
        "categorical_train.loc[categorical_train[\"property_type\"].apply(lambda x : x not in prop_types_to_dummy), \"property_type\"] = \"Other\"\n",
        "categorical_train.loc[categorical_train[\"neighbourhood_cleansed\"].apply(lambda x : x not in hoods_to_dummy), \"neighbourhood_cleansed\"] = \"Other\"\n",
        "categorical_train = pd.get_dummies(categorical_train, prefix=[\"Property Type\", \"Neighborhood\", \"Neighborhood Group\", \"Response Time\", \"Room Type\"],\n",
        "                                   prefix_sep = \" : \", dummy_na=True, drop_first=False).drop(columns=[\"Property Type : nan\",\n",
        "                                                                                                      \"Neighborhood : nan\",\n",
        "                                                                                                      \"Neighborhood Group : nan\",\n",
        "                                                                                                      \"Room Type : nan\"]).astype(int)\n",
        "\n",
        "# Create Indicators for Amenities that appear more than 500 times in training set (maybe add more for more complex models)\n",
        "amenities_as_lists = raw_train['amenities'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\"', '').split(', '))\n",
        "\n",
        "unique_amenities = {}\n",
        "\n",
        "for list in amenities_as_lists:\n",
        "    for item in list:\n",
        "        if item in unique_amenities:\n",
        "            unique_amenities[item] = unique_amenities[item] + 1\n",
        "        else:\n",
        "            unique_amenities[item] = 1\n",
        "\n",
        "amenitities_to_dummy = [amenity for amenity, count in unique_amenities.items() if count >= 100]\n",
        "\n",
        "amenity_train = pd.DataFrame({f'Amenity : {amenity}': amenities_as_lists.apply(lambda x: amenity in x) for amenity in amenitities_to_dummy}).astype(int)\n",
        "amenity_train[\"Total Amenities\"] = amenities_as_lists.apply(lambda x : len(x))\n",
        "\n",
        "# features that require imputation and other wrangling (need to revisit imputation in more complex models)\n",
        "wrangle_train = raw_train[[\"host_response_rate\", \"host_acceptance_rate\", \"bathrooms\", \"bedrooms\", \"beds\"]].copy()\n",
        "\n",
        "wrangle_train.loc[wrangle_train[\"host_response_rate\"].isna(), \"host_response_rate\"] = -1\n",
        "wrangle_train.loc[wrangle_train[\"host_acceptance_rate\"].isna(), \"host_acceptance_rate\"] = -1\n",
        "\n",
        "wrangle_train.loc[wrangle_train[\"bathrooms\"].isna(), \"bathrooms\"] = 1\n",
        "wrangle_train.loc[wrangle_train[\"bedrooms\"].isna(), \"bedrooms\"] = 1\n",
        "wrangle_train.loc[wrangle_train[\"beds\"].isna(), \"beds\"] = 1\n",
        "\n",
        "wrangle_train[\"Shared Baths\"] = raw_train[\"bathrooms_text\"].apply(lambda x : \"shared\" in str(x).lower()).astype(int)\n",
        "wrangle_train[\"Calculated Host Proportion : Entire Homes/Apts\"] = raw_train['calculated_host_listings_count_entire_homes'] / raw_train['calculated_host_listings_count']\n",
        "wrangle_train[\"Calculated Host Proportion : Private Rooms\"] = raw_train['calculated_host_listings_count_private_rooms'] / raw_train['calculated_host_listings_count']\n",
        "wrangle_train[\"Calculated Host Proportion : Shared Rooms\"] = raw_train['calculated_host_listings_count_shared_rooms'] / raw_train['calculated_host_listings_count']\n",
        "\n",
        "# Curate All review Data\n",
        "review_train = raw_train[['first_review', 'last_review',\n",
        "                          'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']].copy()\n",
        "\n",
        "review_train.loc[review_train[\"first_review\"].isna(), 'first_review'] = raw_train[\"first_review\"].max()\n",
        "review_train.loc[review_train[\"last_review\"].isna(), 'last_review'] = raw_train[\"last_review\"].min()\n",
        "review_train[\"first_review\"] = (raw_train[\"first_review\"].max() - review_train[\"first_review\"]).dt.days\n",
        "review_train[\"last_review\"] = (raw_train[\"last_review\"].max() - review_train[\"last_review\"]).dt.days\n",
        "\n",
        "review_train.loc[review_train[\"review_scores_rating\"].isna(), 'review_scores_rating'] = -1\n",
        "review_train.loc[review_train[\"review_scores_accuracy\"].isna(), 'review_scores_accuracy'] = -1\n",
        "review_train.loc[review_train[\"review_scores_cleanliness\"].isna(), 'review_scores_cleanliness'] = -1\n",
        "review_train.loc[review_train[\"review_scores_checkin\"].isna(), 'review_scores_checkin'] = -1\n",
        "review_train.loc[review_train[\"review_scores_communication\"].isna(), 'review_scores_communication'] = -1\n",
        "review_train.loc[review_train[\"review_scores_location\"].isna(), 'review_scores_location'] = -1\n",
        "review_train.loc[review_train[\"review_scores_value\"].isna(), 'review_scores_value'] = -1\n",
        "\n",
        "review_train[\"Has Reviews\"] = (raw_train[\"number_of_reviews\"] == 0).astype(int)\n",
        "\n",
        "# join for final dataframe\n",
        "model2_train = pd.concat([good_to_go_train, bools_train, coords_train, dates_train, categorical_train, amenity_train, wrangle_train, review_train], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLd8NWXqEzF_"
      },
      "source": [
        "## Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOu19JcwEzF_"
      },
      "outputs": [],
      "source": [
        "# features that are ready to go out of the box\n",
        "good_to_go_test = raw_test[['host_total_listings_count', 'calculated_host_listings_count',\n",
        "                              'accommodates',\n",
        "                              'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
        "                              'minimum_nights', 'maximum_nights',\n",
        "                              'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].copy()\n",
        "\n",
        "# features that require transformation from boolean to indicator\n",
        "bools_test = raw_test[['host_is_superhost', \"host_has_profile_pic\", 'host_identity_verified', 'has_availability', 'instant_bookable']].copy()\n",
        "bools_test.loc[bools_test[\"host_is_superhost\"].isna(), 'host_is_superhost'] = False\n",
        "bools_test.loc[bools_test[\"has_availability\"].isna(), 'has_availability'] = False\n",
        "bools_test = bools_test.astype(int)\n",
        "\n",
        "# coordinate and rotated coordinate features\n",
        "coords_test = raw_test[['longitude', 'latitude']].copy()\n",
        "\n",
        "theta = np.radians(32)\n",
        "rotation_matrix = np.array([\n",
        "    [np.cos(theta), -np.sin(theta)],\n",
        "    [np.sin(theta), np.cos(theta)]\n",
        "])\n",
        "\n",
        "coords = coords_test[['longitude', 'latitude']].values\n",
        "rotated_coords = coords @ rotation_matrix.T\n",
        "coords_test['Rotated Longitude'] = rotated_coords[:, 0]\n",
        "coords_test['Rotate Latitude'] = rotated_coords[:, 1]\n",
        "\n",
        "# date variables\n",
        "dates_test = (raw_train[\"host_since\"].max() - raw_test[\"host_since\"]).dt.days\n",
        "\n",
        "# create dummies for categorical vairables\n",
        "categorical_test = raw_test[['property_type', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'host_response_time', 'room_type']].copy()\n",
        "categorical_test.loc[categorical_test[\"property_type\"].apply(lambda x : x not in prop_types_to_dummy), \"property_type\"] = \"Other\"\n",
        "categorical_test.loc[categorical_test[\"neighbourhood_cleansed\"].apply(lambda x : x not in hoods_to_dummy), \"neighbourhood_cleansed\"] = \"Other\"\n",
        "categorical_test = pd.get_dummies(categorical_test, prefix=[\"Property Type\", \"Neighborhood\", \"Neighborhood Group\", \"Response Time\", \"Room Type\"],\n",
        "                                   prefix_sep = \" : \", dummy_na=True, drop_first=False).drop(columns=[\"Property Type : nan\",\n",
        "                                                                                                      \"Neighborhood : nan\",\n",
        "                                                                                                      \"Neighborhood Group : nan\",\n",
        "                                                                                                      \"Room Type : nan\"]).astype(int)\n",
        "\n",
        "# Create Indicators for Amenities that appear more than 500 times in training set (maybe add more for more complex models)\n",
        "amenities_as_lists = raw_test['amenities'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\"', '').split(', '))\n",
        "\n",
        "amenity_test = pd.DataFrame({f'Amenity : {amenity}': amenities_as_lists.apply(lambda x: amenity in x) for amenity in amenitities_to_dummy}).astype(int)\n",
        "amenity_test[\"Total Amenities\"] = amenities_as_lists.apply(lambda x : len(x))\n",
        "\n",
        "# features that require imputation and other wrangling (need to revisit imputation in more complex models)\n",
        "wrangle_test = raw_test[[\"host_response_rate\", \"host_acceptance_rate\", \"bathrooms\", \"bedrooms\", \"beds\"]].copy()\n",
        "\n",
        "wrangle_test.loc[wrangle_test[\"host_response_rate\"].isna(), \"host_response_rate\"] = -1\n",
        "wrangle_test.loc[wrangle_test[\"host_acceptance_rate\"].isna(), \"host_acceptance_rate\"] = -1\n",
        "\n",
        "wrangle_test.loc[wrangle_test[\"bathrooms\"].isna(), \"bathrooms\"] = 1\n",
        "wrangle_test.loc[wrangle_test[\"bedrooms\"].isna(), \"bedrooms\"] = 1\n",
        "wrangle_test.loc[wrangle_test[\"beds\"].isna(), \"beds\"] = 1\n",
        "\n",
        "wrangle_test[\"Shared Baths\"] = raw_test[\"bathrooms_text\"].apply(lambda x : \"shared\" in str(x).lower()).astype(int)\n",
        "wrangle_test[\"Calculated Host Proportion : Entire Homes/Apts\"] = raw_test['calculated_host_listings_count_entire_homes'] / raw_test['calculated_host_listings_count']\n",
        "wrangle_test[\"Calculated Host Proportion : Private Rooms\"] = raw_test['calculated_host_listings_count_private_rooms'] / raw_test['calculated_host_listings_count']\n",
        "wrangle_test[\"Calculated Host Proportion : Shared Rooms\"] = raw_test['calculated_host_listings_count_shared_rooms'] / raw_test['calculated_host_listings_count']\n",
        "\n",
        "# Curate all Review Data\n",
        "review_test = raw_test[['first_review', 'last_review',\n",
        "                          'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']].copy()\n",
        "\n",
        "review_test.loc[review_test[\"first_review\"].isna(), 'first_review'] = raw_train[\"first_review\"].max()\n",
        "review_test.loc[review_test[\"last_review\"].isna(), 'last_review'] = raw_train[\"last_review\"].min()\n",
        "review_test[\"first_review\"] = (raw_train[\"first_review\"].max() - review_test[\"first_review\"]).dt.days\n",
        "review_test[\"last_review\"] = (raw_train[\"last_review\"].max() - review_test[\"last_review\"]).dt.days\n",
        "\n",
        "review_test.loc[review_test[\"review_scores_rating\"].isna(), 'review_scores_rating'] = -1\n",
        "review_test.loc[review_test[\"review_scores_accuracy\"].isna(), 'review_scores_accuracy'] = -1\n",
        "review_test.loc[review_test[\"review_scores_cleanliness\"].isna(), 'review_scores_cleanliness'] = -1\n",
        "review_test.loc[review_test[\"review_scores_checkin\"].isna(), 'review_scores_checkin'] = -1\n",
        "review_test.loc[review_test[\"review_scores_communication\"].isna(), 'review_scores_communication'] = -1\n",
        "review_test.loc[review_test[\"review_scores_location\"].isna(), 'review_scores_location'] = -1\n",
        "review_test.loc[review_test[\"review_scores_value\"].isna(), 'review_scores_value'] = -1\n",
        "\n",
        "review_test[\"Has Reviews\"] = (raw_test[\"number_of_reviews\"] == 0).astype(int)\n",
        "\n",
        "\n",
        "# join for final dataframe\n",
        "model2_test = pd.concat([good_to_go_test, bools_test, coords_test, dates_test, categorical_test, amenity_test, wrangle_test, review_test], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUDmPC1ZEzGB"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3mCF1WvEzGB"
      },
      "outputs": [],
      "source": [
        "model2_train.columns = [x.replace(\"_\", \" \") for x in model2_train.columns]\n",
        "model2_test.columns = [x.replace(\"_\", \" \") for x in model2_test.columns]\n",
        "\n",
        "model2_train_norm = model2_train.copy()\n",
        "model2_test_norm = model2_test.copy()\n",
        "\n",
        "for col in model2_train.columns:\n",
        "    model2_train_norm[col] = model2_train_norm[col] - model2_train[col].min()\n",
        "    model2_train_norm[col] = model2_train_norm[col] / (model2_train[col].max() - model2_train[col].min())\n",
        "\n",
        "    model2_test_norm[col] = model2_test_norm[col] - model2_train[col].min()\n",
        "    model2_test_norm[col] = model2_test_norm[col] / (model2_train[col].max() - model2_train[col].min())\n",
        "\n",
        "model2_train_norm.to_csv('data/model2_training_features.csv', index=False)\n",
        "model2_test_norm.to_csv('data/model2_testing_features.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl1t9nKxEzGC"
      },
      "source": [
        "# Model 3 : Including Textual Data and Dimensionality Reduction\n",
        "\n",
        "## Computing Influential N-Grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ulUDT-zEzGC"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Remove punctuation\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HygPBaAEzGD"
      },
      "outputs": [],
      "source": [
        "clean_descriptions = raw_train['description'].fillna(\"\")\n",
        "\n",
        "clean_names = raw_train['name'].apply(clean_text)\n",
        "clean_descriptions = clean_descriptions.apply(clean_text)\n",
        "\n",
        "name_vectorizer = CountVectorizer(ngram_range=(1, 5), min_df=50)\n",
        "description_vectorizer = CountVectorizer(ngram_range=(1, 5), min_df=100)\n",
        "\n",
        "name_ngrams = pd.DataFrame(name_vectorizer.fit_transform(clean_names).toarray(),\n",
        "                           columns = name_vectorizer.get_feature_names_out())\n",
        "description_ngrams = pd.DataFrame(description_vectorizer.fit_transform(clean_descriptions).toarray(),\n",
        "                                  columns = description_vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HWqGsxJEzGD"
      },
      "outputs": [],
      "source": [
        "name_ngram_mututal_information = mutual_info_regression(name_ngrams, raw_train['price'])\n",
        "description_ngram_mututal_information = mutual_info_regression(description_ngrams, raw_train['price'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_0jbzeYEzGE"
      },
      "outputs": [],
      "source": [
        "name_top100 = [feature for _, feature in sorted(zip(name_ngram_mututal_information, name_ngrams.columns), reverse=True)[:100]]\n",
        "description_top200 = [feature for _, feature in sorted(zip(description_ngram_mututal_information, description_ngrams.columns), reverse=True)[:200]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW7SoSyJEzGE"
      },
      "source": [
        "## Training\\Test Sets and Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKb5FoTpEzGF"
      },
      "outputs": [],
      "source": [
        "clean_descriptions_test = raw_test['description'].fillna(\"\")\n",
        "\n",
        "clean_names_test = raw_test['name'].apply(clean_text)\n",
        "clean_descriptions_test = clean_descriptions_test.apply(clean_text)\n",
        "\n",
        "name_transformer = CountVectorizer(ngram_range=(1, 5), vocabulary=name_top100)\n",
        "description_transformer = CountVectorizer(ngram_range=(1, 5), vocabulary=description_top200)\n",
        "\n",
        "name_ngrams_train = pd.DataFrame(name_transformer.transform(clean_names).toarray(),\n",
        "                                 columns = [f'NGram : {gram}' for gram in name_transformer.get_feature_names_out()])\n",
        "description_ngrams_train = pd.DataFrame(description_transformer.transform(clean_descriptions).toarray(),\n",
        "                                        columns = [f'NGram : {gram}' for gram in description_transformer.get_feature_names_out()])\n",
        "name_ngrams_test = pd.DataFrame(name_transformer.transform(clean_names_test).toarray(),\n",
        "                                columns = [f'NGram : {gram}' for gram in name_transformer.get_feature_names_out()])\n",
        "description_ngrams_test = pd.DataFrame(description_transformer.transform(clean_descriptions_test).toarray(),\n",
        "                                       columns = [f'NGram : {gram}' for gram in description_transformer.get_feature_names_out()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNH6-6HiEzGF"
      },
      "outputs": [],
      "source": [
        "model3_train = pd.concat([model2_train, name_ngrams_train, description_ngrams_train], axis=1)\n",
        "model3_test = pd.concat([model2_test, name_ngrams_test, description_ngrams_test], axis=1)\n",
        "\n",
        "model3_train_norm = model3_train.copy()\n",
        "model3_test_norm = model3_test.copy()\n",
        "\n",
        "for col in model2_train.columns:\n",
        "    model3_train_norm[col] = model3_train_norm[col] - model3_train[col].mean()\n",
        "    model3_train_norm[col] = model3_train_norm[col] / model3_train[col].std()\n",
        "\n",
        "    model3_test_norm[col] = model3_test_norm[col] - model3_train[col].mean()\n",
        "    model3_test_norm[col] = model3_test_norm[col] / model3_train[col].std()\n",
        "\n",
        "model3_train_norm.to_csv('data/model3_training_features.csv', index=False)\n",
        "model3_test_norm.to_csv('data/model3_testing_features.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSy0DMrcEzGG"
      },
      "source": [
        "## Dimension Reduction and Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-or4hm7EzGG",
        "outputId": "88311dc8-5ad5-43e5-f4e3-6deb38999e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7651035724212225\n"
          ]
        }
      ],
      "source": [
        "pca = PCA(n_components=200)\n",
        "pca.fit(model3_train_norm)\n",
        "\n",
        "print(sum(pca.explained_variance_ratio_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRPuHJOkEzGJ"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(pca.transform(model3_train_norm)).to_csv('data/model3_training_features.csv', index=False)\n",
        "pd.DataFrame(pca.transform(model3_test_norm)).to_csv('data/model3_testing_features.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test commit"
      ],
      "metadata": {
        "id": "wOOo40BLE-ch"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}