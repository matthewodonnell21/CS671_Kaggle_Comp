{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybHitVs3EzFs"
   },
   "source": [
    "# Import Packages & Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llfb7Y4HEzFx",
    "outputId": "845a445c-4413-4664-bc67-e269d08d22b4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DzxwEdC2EzF0"
   },
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv(\"data/train.csv\", parse_dates=['host_since', 'first_review', 'last_review'])\n",
    "raw_test = pd.read_csv(\"data/test.csv\", parse_dates=['host_since', 'first_review', 'last_review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acNIw9v-EzF1"
   },
   "source": [
    "# Model 1: Interpretability\n",
    "\n",
    "## Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E_CxYfANEzF2"
   },
   "outputs": [],
   "source": [
    "# features that are ready to go out of the box\n",
    "good_to_go_train = raw_train[['host_total_listings_count', 'calculated_host_listings_count',\n",
    "                              'accommodates',\n",
    "                              'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "                              'minimum_nights', 'maximum_nights',\n",
    "                              'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].copy()\n",
    "\n",
    "# features that require transformation from boolean to indicator\n",
    "bools_train = raw_train[['host_is_superhost', \"host_has_profile_pic\", 'host_identity_verified', 'has_availability', 'instant_bookable']].copy()\n",
    "bools_train.loc[bools_train[\"host_is_superhost\"].isna(), 'host_is_superhost'] = False\n",
    "bools_train.loc[bools_train[\"has_availability\"].isna(), 'has_availability'] = False\n",
    "bools_train = bools_train.astype(int)\n",
    "\n",
    "# coordinate and rotated coordinate features\n",
    "coords_train = raw_train[['longitude', 'latitude']].copy()\n",
    "\n",
    "theta = np.radians(32)\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta), np.cos(theta)]\n",
    "])\n",
    "\n",
    "coords = coords_train[['longitude', 'latitude']].values\n",
    "rotated_coords = coords @ rotation_matrix.T\n",
    "coords_train['Rotated Longitude'] = rotated_coords[:, 0]\n",
    "coords_train['Rotate Latitude'] = rotated_coords[:, 1]\n",
    "\n",
    "# date variables\n",
    "dates_train = (raw_train[\"host_since\"].max() - raw_train[\"host_since\"]).dt.days\n",
    "\n",
    "# create dummies for categorical vairables\n",
    "categorical_train = raw_train[['neighbourhood_group_cleansed', 'host_response_time', 'room_type']].copy()\n",
    "categorical_train = pd.get_dummies(categorical_train, prefix=[\"Neighborhood Group\", \"Response Time\", \"Room Type\"],\n",
    "                                   prefix_sep = \" : \", dummy_na=True, drop_first=False).drop(columns=[\"Neighborhood Group : nan\", \"Room Type : nan\"]).astype(int)\n",
    "\n",
    "# Create Indicators for Amenities that appear more than 500 times in training set (maybe add more for more complex models)\n",
    "amenities_as_lists = raw_train['amenities'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\"', '').split(', '))\n",
    "\n",
    "unique_amenities = {}\n",
    "\n",
    "for list in amenities_as_lists:\n",
    "    for item in list:\n",
    "        if item in unique_amenities:\n",
    "            unique_amenities[item] = unique_amenities[item] + 1\n",
    "        else:\n",
    "            unique_amenities[item] = 1\n",
    "\n",
    "amenitities_to_dummy = [amenity for amenity, count in unique_amenities.items() if count >= 500]\n",
    "\n",
    "amenity_train = pd.DataFrame({f'Amenity : {amenity}': amenities_as_lists.apply(lambda x: amenity in x) for amenity in amenitities_to_dummy}).astype(int)\n",
    "amenity_train[\"Total Amenities\"] = amenities_as_lists.apply(lambda x : len(x))\n",
    "\n",
    "# features that require imputation and other wrangling (need to revisit imputation in more complex models)\n",
    "wrangle_train = raw_train[[\"host_response_rate\", \"host_acceptance_rate\", \"bathrooms\", \"bedrooms\", \"beds\"]].copy()\n",
    "\n",
    "wrangle_train.loc[wrangle_train[\"host_response_rate\"].isna(), \"host_response_rate\"] = -1\n",
    "wrangle_train.loc[wrangle_train[\"host_acceptance_rate\"].isna(), \"host_acceptance_rate\"] = -1\n",
    "\n",
    "wrangle_train.loc[wrangle_train[\"bathrooms\"].isna(), \"bathrooms\"] = 1\n",
    "wrangle_train.loc[wrangle_train[\"bedrooms\"].isna(), \"bedrooms\"] = 1\n",
    "wrangle_train.loc[wrangle_train[\"beds\"].isna(), \"beds\"] = 1\n",
    "\n",
    "wrangle_train[\"Shared Baths\"] = raw_train[\"bathrooms_text\"].apply(lambda x : \"shared\" in str(x).lower()).astype(int)\n",
    "wrangle_train[\"Calculated Host Proportion : Entire Homes/Apts\"] = raw_train['calculated_host_listings_count_entire_homes'] / raw_train['calculated_host_listings_count']\n",
    "wrangle_train[\"Calculated Host Proportion : Private Rooms\"] = raw_train['calculated_host_listings_count_private_rooms'] / raw_train['calculated_host_listings_count']\n",
    "wrangle_train[\"Calculated Host Proportion : Shared Rooms\"] = raw_train['calculated_host_listings_count_shared_rooms'] / raw_train['calculated_host_listings_count']\n",
    "\n",
    "# join for final dataframe\n",
    "model1_train = pd.concat([good_to_go_train, bools_train, coords_train, dates_train, categorical_train, amenity_train, wrangle_train], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQKdLEmpEzF4"
   },
   "source": [
    "## Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hOXtRRitEzF4"
   },
   "outputs": [],
   "source": [
    "# features that are ready to go out of the box\n",
    "good_to_go_test = raw_test[['host_total_listings_count', 'calculated_host_listings_count',\n",
    "                              'accommodates',\n",
    "                              'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "                              'minimum_nights', 'maximum_nights',\n",
    "                              'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].copy()\n",
    "\n",
    "# features that require transformation from boolean to indicator\n",
    "bools_test = raw_test[['host_is_superhost', \"host_has_profile_pic\", 'host_identity_verified', 'has_availability', 'instant_bookable']].copy()\n",
    "bools_test.loc[bools_test[\"host_is_superhost\"].isna(), 'host_is_superhost'] = False\n",
    "bools_test.loc[bools_test[\"has_availability\"].isna(), 'has_availability'] = False\n",
    "bools_test = bools_test.astype(int)\n",
    "\n",
    "# coordinate and rotated coordinate features\n",
    "coords_test = raw_test[['longitude', 'latitude']].copy()\n",
    "\n",
    "theta = np.radians(32)\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta), np.cos(theta)]\n",
    "])\n",
    "\n",
    "coords = coords_test[['longitude', 'latitude']].values\n",
    "rotated_coords = coords @ rotation_matrix.T\n",
    "coords_test['Rotated Longitude'] = rotated_coords[:, 0]\n",
    "coords_test['Rotate Latitude'] = rotated_coords[:, 1]\n",
    "\n",
    "# date variables\n",
    "dates_test = (raw_train[\"host_since\"].max() - raw_test[\"host_since\"]).dt.days\n",
    "\n",
    "# create dummies for categorical vairables\n",
    "categorical_test = raw_test[['neighbourhood_group_cleansed', 'host_response_time', 'room_type']].copy()\n",
    "categorical_test = pd.get_dummies(categorical_test, prefix=[\"Neighborhood Group\", \"Response Time\", \"Room Type\"],\n",
    "                                   prefix_sep = \" : \", dummy_na=True, drop_first=False).drop(columns=[\"Neighborhood Group : nan\", \"Room Type : nan\"]).astype(int)\n",
    "\n",
    "# Create Indicators for Amenities that appear more than 500 times in training set (maybe add more for more complex models)\n",
    "amenities_as_lists = raw_test['amenities'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\"', '').split(', '))\n",
    "\n",
    "amenity_test = pd.DataFrame({f'Amenity : {amenity}': amenities_as_lists.apply(lambda x: amenity in x) for amenity in amenitities_to_dummy}).astype(int)\n",
    "amenity_test[\"Total Amenities\"] = amenities_as_lists.apply(lambda x : len(x))\n",
    "\n",
    "# features that require imputation and other wrangling (need to revisit imputation in more complex models)\n",
    "wrangle_test = raw_test[[\"host_response_rate\", \"host_acceptance_rate\", \"bathrooms\", \"bedrooms\", \"beds\"]].copy()\n",
    "\n",
    "wrangle_test.loc[wrangle_test[\"host_response_rate\"].isna(), \"host_response_rate\"] = -1\n",
    "wrangle_test.loc[wrangle_test[\"host_acceptance_rate\"].isna(), \"host_acceptance_rate\"] = -1\n",
    "\n",
    "wrangle_test.loc[wrangle_test[\"bathrooms\"].isna(), \"bathrooms\"] = 1\n",
    "wrangle_test.loc[wrangle_test[\"bedrooms\"].isna(), \"bedrooms\"] = 1\n",
    "wrangle_test.loc[wrangle_test[\"beds\"].isna(), \"beds\"] = 1\n",
    "\n",
    "wrangle_test[\"Shared Baths\"] = raw_test[\"bathrooms_text\"].apply(lambda x : \"shared\" in str(x).lower()).astype(int)\n",
    "wrangle_test[\"Calculated Host Proportion : Entire Homes/Apts\"] = raw_test['calculated_host_listings_count_entire_homes'] / raw_test['calculated_host_listings_count']\n",
    "wrangle_test[\"Calculated Host Proportion : Private Rooms\"] = raw_test['calculated_host_listings_count_private_rooms'] / raw_test['calculated_host_listings_count']\n",
    "wrangle_test[\"Calculated Host Proportion : Shared Rooms\"] = raw_test['calculated_host_listings_count_shared_rooms'] / raw_test['calculated_host_listings_count']\n",
    "\n",
    "# join for final dataframe\n",
    "model1_test = pd.concat([good_to_go_test, bools_test, coords_test, dates_test, categorical_test, amenity_test, wrangle_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJMDbgeEEzF6"
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Jl0jAZWGEzF6"
   },
   "outputs": [],
   "source": [
    "model1_train.columns = [x.replace(\"_\", \" \") for x in model1_train.columns]\n",
    "model1_test.columns = [x.replace(\"_\", \" \") for x in model1_test.columns]\n",
    "\n",
    "model1_train_norm = model1_train.copy()\n",
    "model1_test_norm = model1_test.copy()\n",
    "\n",
    "for col in model1_train.columns:\n",
    "    model1_train_norm[col] = model1_train_norm[col] - model1_train[col].min()\n",
    "    model1_train_norm[col] = model1_train_norm[col] / (model1_train[col].max() - model1_train[col].min())\n",
    "\n",
    "    model1_test_norm[col] = model1_test_norm[col] - model1_train[col].min()\n",
    "    model1_test_norm[col] = model1_test_norm[col] / (model1_train[col].max() - model1_train[col].min())\n",
    "\n",
    "model1_train_norm.to_csv('data/model1_training_features.csv', index=False)\n",
    "model1_test_norm.to_csv('data/model1_testing_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SvUiHBHEzF7"
   },
   "source": [
    "# Model 2 : Increasing Complexity and Amount of Data\n",
    "## Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Dc15TGrXEzF9"
   },
   "outputs": [],
   "source": [
    "# features that are ready to go out of the box\n",
    "good_to_go_train = raw_train[['host_total_listings_count', 'calculated_host_listings_count',\n",
    "                              'accommodates',\n",
    "                              'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "                              'minimum_nights', 'maximum_nights',\n",
    "                              'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].copy()\n",
    "\n",
    "# features that require transformation from boolean to indicator\n",
    "bools_train = raw_train[['host_is_superhost', \"host_has_profile_pic\", 'host_identity_verified', 'has_availability', 'instant_bookable']].copy()\n",
    "bools_train.loc[bools_train[\"host_is_superhost\"].isna(), 'host_is_superhost'] = False\n",
    "bools_train.loc[bools_train[\"has_availability\"].isna(), 'has_availability'] = False\n",
    "bools_train = bools_train.astype(int)\n",
    "\n",
    "# coordinate and rotated coordinate features\n",
    "coords_train = raw_train[['longitude', 'latitude']].copy()\n",
    "\n",
    "theta = np.radians(32)\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta), np.cos(theta)]\n",
    "])\n",
    "\n",
    "coords = coords_train[['longitude', 'latitude']].values\n",
    "rotated_coords = coords @ rotation_matrix.T\n",
    "coords_train['Rotated Longitude'] = rotated_coords[:, 0]\n",
    "coords_train['Rotate Latitude'] = rotated_coords[:, 1]\n",
    "\n",
    "# date variables\n",
    "dates_train = (raw_train[\"host_since\"].max() - raw_train[\"host_since\"]).dt.days\n",
    "\n",
    "# create dummies for categorical vairables\n",
    "hoods = raw_train[\"neighbourhood_cleansed\"].value_counts()\n",
    "hoods_to_dummy = (hoods[hoods >= 20].index).tolist()\n",
    "\n",
    "prop_types = raw_train[\"property_type\"].value_counts()\n",
    "prop_types_to_dummy = (prop_types[prop_types >= 20].index).tolist()\n",
    "\n",
    "categorical_train = raw_train[['property_type', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'host_response_time', 'room_type']].copy()\n",
    "categorical_train.loc[categorical_train[\"property_type\"].apply(lambda x : x not in prop_types_to_dummy), \"property_type\"] = \"Other\"\n",
    "categorical_train.loc[categorical_train[\"neighbourhood_cleansed\"].apply(lambda x : x not in hoods_to_dummy), \"neighbourhood_cleansed\"] = \"Other\"\n",
    "categorical_train = pd.get_dummies(categorical_train, prefix=[\"Property Type\", \"Neighborhood\", \"Neighborhood Group\", \"Response Time\", \"Room Type\"],\n",
    "                                   prefix_sep = \" : \", dummy_na=True, drop_first=False).drop(columns=[\"Property Type : nan\",\n",
    "                                                                                                      \"Neighborhood : nan\",\n",
    "                                                                                                      \"Neighborhood Group : nan\",\n",
    "                                                                                                      \"Room Type : nan\"]).astype(int)\n",
    "\n",
    "# Create Indicators for Amenities that appear more than 500 times in training set (maybe add more for more complex models)\n",
    "amenities_as_lists = raw_train['amenities'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\"', '').split(', '))\n",
    "\n",
    "unique_amenities = {}\n",
    "\n",
    "for list in amenities_as_lists:\n",
    "    for item in list:\n",
    "        if item in unique_amenities:\n",
    "            unique_amenities[item] = unique_amenities[item] + 1\n",
    "        else:\n",
    "            unique_amenities[item] = 1\n",
    "\n",
    "amenitities_to_dummy = [amenity for amenity, count in unique_amenities.items() if count >= 100]\n",
    "\n",
    "amenity_train = pd.DataFrame({f'Amenity : {amenity}': amenities_as_lists.apply(lambda x: amenity in x) for amenity in amenitities_to_dummy}).astype(int)\n",
    "amenity_train[\"Total Amenities\"] = amenities_as_lists.apply(lambda x : len(x))\n",
    "\n",
    "# features that require imputation and other wrangling (need to revisit imputation in more complex models)\n",
    "wrangle_train = raw_train[[\"host_response_rate\", \"host_acceptance_rate\", \"bathrooms\", \"bedrooms\", \"beds\"]].copy()\n",
    "\n",
    "wrangle_train.loc[wrangle_train[\"host_response_rate\"].isna(), \"host_response_rate\"] = -1\n",
    "wrangle_train.loc[wrangle_train[\"host_acceptance_rate\"].isna(), \"host_acceptance_rate\"] = -1\n",
    "\n",
    "wrangle_train.loc[wrangle_train[\"bathrooms\"].isna(), \"bathrooms\"] = 1\n",
    "wrangle_train.loc[wrangle_train[\"bedrooms\"].isna(), \"bedrooms\"] = 1\n",
    "wrangle_train.loc[wrangle_train[\"beds\"].isna(), \"beds\"] = 1\n",
    "\n",
    "wrangle_train[\"Shared Baths\"] = raw_train[\"bathrooms_text\"].apply(lambda x : \"shared\" in str(x).lower()).astype(int)\n",
    "wrangle_train[\"Calculated Host Proportion : Entire Homes/Apts\"] = raw_train['calculated_host_listings_count_entire_homes'] / raw_train['calculated_host_listings_count']\n",
    "wrangle_train[\"Calculated Host Proportion : Private Rooms\"] = raw_train['calculated_host_listings_count_private_rooms'] / raw_train['calculated_host_listings_count']\n",
    "wrangle_train[\"Calculated Host Proportion : Shared Rooms\"] = raw_train['calculated_host_listings_count_shared_rooms'] / raw_train['calculated_host_listings_count']\n",
    "\n",
    "# Curate All review Data\n",
    "review_train = raw_train[['first_review', 'last_review',\n",
    "                          'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']].copy()\n",
    "\n",
    "review_train.loc[review_train[\"first_review\"].isna(), 'first_review'] = raw_train[\"first_review\"].max()\n",
    "review_train.loc[review_train[\"last_review\"].isna(), 'last_review'] = raw_train[\"last_review\"].min()\n",
    "review_train[\"first_review\"] = (raw_train[\"first_review\"].max() - review_train[\"first_review\"]).dt.days\n",
    "review_train[\"last_review\"] = (raw_train[\"last_review\"].max() - review_train[\"last_review\"]).dt.days\n",
    "\n",
    "review_train.loc[review_train[\"review_scores_rating\"].isna(), 'review_scores_rating'] = -1\n",
    "review_train.loc[review_train[\"review_scores_accuracy\"].isna(), 'review_scores_accuracy'] = -1\n",
    "review_train.loc[review_train[\"review_scores_cleanliness\"].isna(), 'review_scores_cleanliness'] = -1\n",
    "review_train.loc[review_train[\"review_scores_checkin\"].isna(), 'review_scores_checkin'] = -1\n",
    "review_train.loc[review_train[\"review_scores_communication\"].isna(), 'review_scores_communication'] = -1\n",
    "review_train.loc[review_train[\"review_scores_location\"].isna(), 'review_scores_location'] = -1\n",
    "review_train.loc[review_train[\"review_scores_value\"].isna(), 'review_scores_value'] = -1\n",
    "\n",
    "review_train[\"Has Reviews\"] = (raw_train[\"number_of_reviews\"] == 0).astype(int)\n",
    "\n",
    "# join for final dataframe\n",
    "model2_train = pd.concat([good_to_go_train, bools_train, coords_train, dates_train, categorical_train, amenity_train, wrangle_train, review_train], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLd8NWXqEzF_"
   },
   "source": [
    "## Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cOu19JcwEzF_"
   },
   "outputs": [],
   "source": [
    "# features that are ready to go out of the box\n",
    "good_to_go_test = raw_test[['host_total_listings_count', 'calculated_host_listings_count',\n",
    "                              'accommodates',\n",
    "                              'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "                              'minimum_nights', 'maximum_nights',\n",
    "                              'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d']].copy()\n",
    "\n",
    "# features that require transformation from boolean to indicator\n",
    "bools_test = raw_test[['host_is_superhost', \"host_has_profile_pic\", 'host_identity_verified', 'has_availability', 'instant_bookable']].copy()\n",
    "bools_test.loc[bools_test[\"host_is_superhost\"].isna(), 'host_is_superhost'] = False\n",
    "bools_test.loc[bools_test[\"has_availability\"].isna(), 'has_availability'] = False\n",
    "bools_test = bools_test.astype(int)\n",
    "\n",
    "# coordinate and rotated coordinate features\n",
    "coords_test = raw_test[['longitude', 'latitude']].copy()\n",
    "\n",
    "theta = np.radians(32)\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta), np.cos(theta)]\n",
    "])\n",
    "\n",
    "coords = coords_test[['longitude', 'latitude']].values\n",
    "rotated_coords = coords @ rotation_matrix.T\n",
    "coords_test['Rotated Longitude'] = rotated_coords[:, 0]\n",
    "coords_test['Rotate Latitude'] = rotated_coords[:, 1]\n",
    "\n",
    "# date variables\n",
    "dates_test = (raw_train[\"host_since\"].max() - raw_test[\"host_since\"]).dt.days\n",
    "\n",
    "# create dummies for categorical vairables\n",
    "categorical_test = raw_test[['property_type', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'host_response_time', 'room_type']].copy()\n",
    "categorical_test.loc[categorical_test[\"property_type\"].apply(lambda x : x not in prop_types_to_dummy), \"property_type\"] = \"Other\"\n",
    "categorical_test.loc[categorical_test[\"neighbourhood_cleansed\"].apply(lambda x : x not in hoods_to_dummy), \"neighbourhood_cleansed\"] = \"Other\"\n",
    "categorical_test = pd.get_dummies(categorical_test, prefix=[\"Property Type\", \"Neighborhood\", \"Neighborhood Group\", \"Response Time\", \"Room Type\"],\n",
    "                                   prefix_sep = \" : \", dummy_na=True, drop_first=False).drop(columns=[\"Property Type : nan\",\n",
    "                                                                                                      \"Neighborhood : nan\",\n",
    "                                                                                                      \"Neighborhood Group : nan\",\n",
    "                                                                                                      \"Room Type : nan\"]).astype(int)\n",
    "\n",
    "# Create Indicators for Amenities that appear more than 500 times in training set (maybe add more for more complex models)\n",
    "amenities_as_lists = raw_test['amenities'].apply(lambda x: x.replace('[', '').replace(']', '').replace('\"', '').split(', '))\n",
    "\n",
    "amenity_test = pd.DataFrame({f'Amenity : {amenity}': amenities_as_lists.apply(lambda x: amenity in x) for amenity in amenitities_to_dummy}).astype(int)\n",
    "amenity_test[\"Total Amenities\"] = amenities_as_lists.apply(lambda x : len(x))\n",
    "\n",
    "# features that require imputation and other wrangling (need to revisit imputation in more complex models)\n",
    "wrangle_test = raw_test[[\"host_response_rate\", \"host_acceptance_rate\", \"bathrooms\", \"bedrooms\", \"beds\"]].copy()\n",
    "\n",
    "wrangle_test.loc[wrangle_test[\"host_response_rate\"].isna(), \"host_response_rate\"] = -1\n",
    "wrangle_test.loc[wrangle_test[\"host_acceptance_rate\"].isna(), \"host_acceptance_rate\"] = -1\n",
    "\n",
    "wrangle_test.loc[wrangle_test[\"bathrooms\"].isna(), \"bathrooms\"] = 1\n",
    "wrangle_test.loc[wrangle_test[\"bedrooms\"].isna(), \"bedrooms\"] = 1\n",
    "wrangle_test.loc[wrangle_test[\"beds\"].isna(), \"beds\"] = 1\n",
    "\n",
    "wrangle_test[\"Shared Baths\"] = raw_test[\"bathrooms_text\"].apply(lambda x : \"shared\" in str(x).lower()).astype(int)\n",
    "wrangle_test[\"Calculated Host Proportion : Entire Homes/Apts\"] = raw_test['calculated_host_listings_count_entire_homes'] / raw_test['calculated_host_listings_count']\n",
    "wrangle_test[\"Calculated Host Proportion : Private Rooms\"] = raw_test['calculated_host_listings_count_private_rooms'] / raw_test['calculated_host_listings_count']\n",
    "wrangle_test[\"Calculated Host Proportion : Shared Rooms\"] = raw_test['calculated_host_listings_count_shared_rooms'] / raw_test['calculated_host_listings_count']\n",
    "\n",
    "# Curate all Review Data\n",
    "review_test = raw_test[['first_review', 'last_review',\n",
    "                          'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']].copy()\n",
    "\n",
    "review_test.loc[review_test[\"first_review\"].isna(), 'first_review'] = raw_train[\"first_review\"].max()\n",
    "review_test.loc[review_test[\"last_review\"].isna(), 'last_review'] = raw_train[\"last_review\"].min()\n",
    "review_test[\"first_review\"] = (raw_train[\"first_review\"].max() - review_test[\"first_review\"]).dt.days\n",
    "review_test[\"last_review\"] = (raw_train[\"last_review\"].max() - review_test[\"last_review\"]).dt.days\n",
    "\n",
    "review_test.loc[review_test[\"review_scores_rating\"].isna(), 'review_scores_rating'] = -1\n",
    "review_test.loc[review_test[\"review_scores_accuracy\"].isna(), 'review_scores_accuracy'] = -1\n",
    "review_test.loc[review_test[\"review_scores_cleanliness\"].isna(), 'review_scores_cleanliness'] = -1\n",
    "review_test.loc[review_test[\"review_scores_checkin\"].isna(), 'review_scores_checkin'] = -1\n",
    "review_test.loc[review_test[\"review_scores_communication\"].isna(), 'review_scores_communication'] = -1\n",
    "review_test.loc[review_test[\"review_scores_location\"].isna(), 'review_scores_location'] = -1\n",
    "review_test.loc[review_test[\"review_scores_value\"].isna(), 'review_scores_value'] = -1\n",
    "\n",
    "review_test[\"Has Reviews\"] = (raw_test[\"number_of_reviews\"] == 0).astype(int)\n",
    "\n",
    "\n",
    "# join for final dataframe\n",
    "model2_test = pd.concat([good_to_go_test, bools_test, coords_test, dates_test, categorical_test, amenity_test, wrangle_test, review_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUDmPC1ZEzGB"
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g3mCF1WvEzGB"
   },
   "outputs": [],
   "source": [
    "model2_train.columns = [x.replace(\"_\", \" \") for x in model2_train.columns]\n",
    "model2_test.columns = [x.replace(\"_\", \" \") for x in model2_test.columns]\n",
    "\n",
    "model2_train_norm = model2_train.copy()\n",
    "model2_test_norm = model2_test.copy()\n",
    "\n",
    "for col in model2_train.columns:\n",
    "    model2_train_norm[col] = model2_train_norm[col] - model2_train[col].min()\n",
    "    model2_train_norm[col] = model2_train_norm[col] / (model2_train[col].max() - model2_train[col].min())\n",
    "\n",
    "    model2_test_norm[col] = model2_test_norm[col] - model2_train[col].min()\n",
    "    model2_test_norm[col] = model2_test_norm[col] / (model2_train[col].max() - model2_train[col].min())\n",
    "\n",
    "model2_train_norm.to_csv('data/model2_training_features.csv', index=False)\n",
    "model2_test_norm.to_csv('data/model2_testing_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gl1t9nKxEzGC"
   },
   "source": [
    "# Model 3 : Including Textual Data\n",
    "\n",
    "## Computing Influential N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9ulUDT-zEzGC"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Remove punctuation\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1HygPBaAEzGD"
   },
   "outputs": [],
   "source": [
    "clean_descriptions = raw_train['description'].fillna(\"\")\n",
    "clean_reviews = raw_train['reviews'].fillna(\"\")\n",
    "\n",
    "clean_names = raw_train['name'].apply(clean_text)\n",
    "clean_descriptions = clean_descriptions.apply(clean_text)\n",
    "clean_reviews = clean_reviews.apply(clean_text).apply(lambda x : re.sub(r'\\n', '', x))\n",
    "\n",
    "name_vectorizer = CountVectorizer(ngram_range=(1, 5), min_df=50)\n",
    "description_vectorizer = CountVectorizer(ngram_range=(2, 6), min_df=150)\n",
    "review_vectorizer = CountVectorizer(ngram_range=(3, 3), min_df=350)\n",
    "\n",
    "name_ngrams = pd.DataFrame(name_vectorizer.fit_transform(clean_names).toarray(),\n",
    "                           columns = name_vectorizer.get_feature_names_out())\n",
    "description_ngrams = pd.DataFrame(description_vectorizer.fit_transform(clean_descriptions).toarray(),\n",
    "                                  columns = description_vectorizer.get_feature_names_out())\n",
    "review_ngrams = pd.DataFrame(review_vectorizer.fit_transform(clean_reviews).toarray(),\n",
    "                                  columns = review_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6HWqGsxJEzGD"
   },
   "outputs": [],
   "source": [
    "name_ngram_mututal_information = mutual_info_regression(name_ngrams, raw_train['price'])\n",
    "description_ngram_mututal_information = mutual_info_regression(description_ngrams, raw_train['price'])\n",
    "review_ngram_mututal_information = mutual_info_regression(review_ngrams, raw_train['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Y_0jbzeYEzGE"
   },
   "outputs": [],
   "source": [
    "name_top50 = [feature for _, feature in sorted(zip(name_ngram_mututal_information, name_ngrams.columns), reverse=True)[:50]]\n",
    "description_top100 = [feature for _, feature in sorted(zip(description_ngram_mututal_information, description_ngrams.columns), reverse=True)[:100]]\n",
    "review_top100 = [feature for _, feature in sorted(zip(review_ngram_mututal_information, review_ngrams.columns), reverse=True)[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW7SoSyJEzGE"
   },
   "source": [
    "## Training\\Test Sets and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oKb5FoTpEzGF"
   },
   "outputs": [],
   "source": [
    "clean_descriptions_test = raw_test['description'].fillna(\"\")\n",
    "clean_reviews_test = raw_test['reviews'].fillna(\"\")\n",
    "\n",
    "clean_names_test = raw_test['name'].apply(clean_text)\n",
    "clean_descriptions_test = clean_descriptions_test.apply(clean_text)\n",
    "clean_reviews_test = clean_reviews_test.apply(clean_text).apply(lambda x : re.sub(r'\\n', '', x))\n",
    "\n",
    "\n",
    "name_transformer = CountVectorizer(ngram_range=(1, 5), vocabulary=name_top50)\n",
    "description_transformer = CountVectorizer(ngram_range=(2, 6), vocabulary=description_top100)\n",
    "review_transformer = CountVectorizer(ngram_range=(3, 3), vocabulary=review_top100)\n",
    "\n",
    "name_ngrams_train = pd.DataFrame(name_transformer.transform(clean_names).toarray(),\n",
    "                                 columns = [f'Name NGram : {gram}' for gram in name_transformer.get_feature_names_out()])\n",
    "description_ngrams_train = pd.DataFrame(description_transformer.transform(clean_descriptions).toarray(),\n",
    "                                        columns = [f'Description NGram : {gram}' for gram in description_transformer.get_feature_names_out()])\n",
    "review_ngrams_train = pd.DataFrame(review_transformer.transform(clean_reviews).toarray(),\n",
    "                                        columns = [f'Review NGram : {gram}' for gram in review_transformer.get_feature_names_out()])\n",
    "\n",
    "name_ngrams_test = pd.DataFrame(name_transformer.transform(clean_names_test).toarray(),\n",
    "                                columns = [f'Name NGram : {gram}' for gram in name_transformer.get_feature_names_out()])\n",
    "description_ngrams_test = pd.DataFrame(description_transformer.transform(clean_descriptions_test).toarray(),\n",
    "                                       columns = [f'Description NGram : {gram}' for gram in description_transformer.get_feature_names_out()])\n",
    "review_ngrams_test = pd.DataFrame(review_transformer.transform(clean_reviews_test).toarray(),\n",
    "                                        columns = [f'Review NGram : {gram}' for gram in review_transformer.get_feature_names_out()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FNH6-6HiEzGF"
   },
   "outputs": [],
   "source": [
    "model3_train = pd.concat([model2_train, name_ngrams_train, description_ngrams_train, review_ngrams_train], axis=1)\n",
    "model3_test = pd.concat([model2_test, name_ngrams_test, description_ngrams_test, review_ngrams_test], axis=1)\n",
    "\n",
    "model3_train_norm = model3_train.copy()\n",
    "model3_test_norm = model3_test.copy()\n",
    "\n",
    "for col in model2_train.columns:\n",
    "    model3_train_norm[col] = model3_train_norm[col] - model3_train[col].mean()\n",
    "    model3_train_norm[col] = model3_train_norm[col] / model3_train[col].std()\n",
    "\n",
    "    model3_test_norm[col] = model3_test_norm[col] - model3_train[col].mean()\n",
    "    model3_test_norm[col] = model3_test_norm[col] / model3_train[col].std()\n",
    "\n",
    "model3_train_norm.to_csv('data/model3_training_features.csv', index=False)\n",
    "model3_test_norm.to_csv('data/model3_testing_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['was great host',\n",
       " 'would definitely stay',\n",
       " 'enjoyed our stay',\n",
       " 'perfect for our',\n",
       " 'very responsive and',\n",
       " 'with lots of',\n",
       " 'was wonderful host',\n",
       " 'everything we needed',\n",
       " 'the apartment itself',\n",
       " 'the apartment is',\n",
       " 'has everything you',\n",
       " 'had everything we',\n",
       " 'responsive and helpful',\n",
       " 'my first time',\n",
       " 'recommend staying here',\n",
       " 'we loved the',\n",
       " 'great host we',\n",
       " 'apartment was clean',\n",
       " 'the location was',\n",
       " 'that we were',\n",
       " 'my partner and',\n",
       " 'place is beautiful',\n",
       " 'loved the neighborhood',\n",
       " 'kitchen was well',\n",
       " 'to work with',\n",
       " 'we enjoyed our',\n",
       " 'super clean and',\n",
       " 'was perfect for',\n",
       " 'great host and',\n",
       " 'the neighborhood is',\n",
       " 'at home and',\n",
       " 'for our family',\n",
       " 'clean and tidy',\n",
       " 'the place is',\n",
       " 'the room is',\n",
       " 'clean and had',\n",
       " 'which takes you',\n",
       " 'we had everything',\n",
       " 'avons passé un',\n",
       " 'neighborhood felt safe',\n",
       " 'we needed and',\n",
       " 'in the area',\n",
       " 'close to lots',\n",
       " 'would definitely recommend',\n",
       " 'apartment is in',\n",
       " 'so it was',\n",
       " 'again great location',\n",
       " 'and made me',\n",
       " 'in the kitchen',\n",
       " 'with everything you',\n",
       " 'hope to be',\n",
       " 'and the bed',\n",
       " 'minute walk to',\n",
       " 'equipped with everything',\n",
       " 'check in was',\n",
       " 'from the metro',\n",
       " 'even though the',\n",
       " 'easy to find',\n",
       " 've stayed in',\n",
       " 'stay in brooklyn',\n",
       " 'were able to',\n",
       " 'definitely stay here',\n",
       " 'clean and well',\n",
       " 'to manhattan the',\n",
       " 'walk to the',\n",
       " 'during our stay',\n",
       " 'in the apartment',\n",
       " 'with all the',\n",
       " 'she was very',\n",
       " 'and the apartment',\n",
       " 'plenty of room',\n",
       " 'was easy to',\n",
       " 'place is clean',\n",
       " 'the neighborhood and',\n",
       " 'well maintained and',\n",
       " 'would highly recommend',\n",
       " 'were looking for',\n",
       " 'but it is',\n",
       " 'location great place',\n",
       " 'quick to respond',\n",
       " 'the neighborhood has',\n",
       " 'host the room',\n",
       " 'loved everything about',\n",
       " 'perfect for us',\n",
       " 'easy to get',\n",
       " 'this apartment to',\n",
       " 'it had everything',\n",
       " 'would recommend it',\n",
       " 'nice and clean',\n",
       " 'it was very',\n",
       " 'and close to',\n",
       " 'family of four',\n",
       " 'in the heart',\n",
       " 'times square and',\n",
       " 'stay again and',\n",
       " 'was very clean',\n",
       " 'the place was',\n",
       " 'great location and',\n",
       " 'place is very',\n",
       " 'is quiet and']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_top100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10 10 recommend</th>\n",
       "      <th>10 10 would</th>\n",
       "      <th>10 min walk</th>\n",
       "      <th>10 minute walk</th>\n",
       "      <th>10 minutes walk</th>\n",
       "      <th>10 would recommend</th>\n",
       "      <th>15 min walk</th>\n",
       "      <th>15 minute walk</th>\n",
       "      <th>able to accommodate</th>\n",
       "      <th>able to check</th>\n",
       "      <th>...</th>\n",
       "      <th>you want to</th>\n",
       "      <th>you will be</th>\n",
       "      <th>you will find</th>\n",
       "      <th>you will have</th>\n",
       "      <th>you will need</th>\n",
       "      <th>you will not</th>\n",
       "      <th>you won be</th>\n",
       "      <th>you won regret</th>\n",
       "      <th>you would need</th>\n",
       "      <th>your stay in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15691</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15692</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15693</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15694</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15695</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15696 rows × 3653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10 10 recommend  10 10 would  10 min walk  10 minute walk  \\\n",
       "0                    0            0            0               0   \n",
       "1                    0            1            0               0   \n",
       "2                    0            0            0               0   \n",
       "3                    0            0            0               0   \n",
       "4                    0            0            0               0   \n",
       "...                ...          ...          ...             ...   \n",
       "15691                0            1            0               0   \n",
       "15692                0            0            0               0   \n",
       "15693                0            0            0               0   \n",
       "15694                0            0            0               0   \n",
       "15695                0            0            0               0   \n",
       "\n",
       "       10 minutes walk  10 would recommend  15 min walk  15 minute walk  \\\n",
       "0                    1                   0            0               0   \n",
       "1                    0                   0            0               0   \n",
       "2                    0                   0            0               0   \n",
       "3                    0                   0            0               0   \n",
       "4                    0                   0            0               0   \n",
       "...                ...                 ...          ...             ...   \n",
       "15691                0                   0            0               0   \n",
       "15692                0                   0            0               0   \n",
       "15693                0                   0            0               0   \n",
       "15694                0                   0            0               0   \n",
       "15695                0                   0            0               0   \n",
       "\n",
       "       able to accommodate  able to check  ...  you want to  you will be  \\\n",
       "0                        0              0  ...            1            0   \n",
       "1                        0              0  ...            0            0   \n",
       "2                        0              0  ...            0            0   \n",
       "3                        0              0  ...            0            0   \n",
       "4                        0              0  ...            0            0   \n",
       "...                    ...            ...  ...          ...          ...   \n",
       "15691                    0              0  ...            0            0   \n",
       "15692                    0              0  ...            0            0   \n",
       "15693                    0              0  ...            0            0   \n",
       "15694                    0              0  ...            0            0   \n",
       "15695                    0              0  ...            0            0   \n",
       "\n",
       "       you will find  you will have  you will need  you will not  you won be  \\\n",
       "0                  0              0              1             0           0   \n",
       "1                  0              0              0             0           0   \n",
       "2                  0              0              0             0           0   \n",
       "3                  0              0              0             0           0   \n",
       "4                  0              0              0             0           0   \n",
       "...              ...            ...            ...           ...         ...   \n",
       "15691              0              0              0             0           0   \n",
       "15692              0              0              0             0           0   \n",
       "15693              0              0              0             0           0   \n",
       "15694              0              0              0             0           0   \n",
       "15695              0              0              0             0           0   \n",
       "\n",
       "       you won regret  you would need  your stay in  \n",
       "0                   1               0             0  \n",
       "1                   0               0             0  \n",
       "2                   0               0             0  \n",
       "3                   0               0             0  \n",
       "4                   0               0             0  \n",
       "...               ...             ...           ...  \n",
       "15691               0               0             0  \n",
       "15692               0               0             0  \n",
       "15693               0               0             0  \n",
       "15694               0               0             0  \n",
       "15695               0               0             0  \n",
       "\n",
       "[15696 rows x 3653 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_ngrams"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
